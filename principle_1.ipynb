{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principle 1: Preferential Attachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import openai\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "import collections \n",
    "import scipy.stats as stats\n",
    "import netgraph\n",
    "import powerlaw as pwl\n",
    "import seaborn as sns\n",
    "import replicate\n",
    "import anthropic\n",
    "import hashlib\n",
    "from utils import get_response, summarize_reasons\n",
    "\n",
    "MEDIUM_SIZE = 24\n",
    "SMALL_SIZE = 0.85 * MEDIUM_SIZE\n",
    "BIGGER_SIZE = 1.5 * MEDIUM_SIZE\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "               \n",
    "def draw_graph(G, ax, G0=None, use_netgraph=True, nodecolor='#d35400'):\n",
    "    if not G0:\n",
    "        G0_edges = set()\n",
    "    else:\n",
    "        G0_edges = set(G0.edges())\n",
    "    G_edges = set(G.edges()) - G0_edges\n",
    "    if not use_netgraph:\n",
    "        pos = nx.spring_layout(G)\n",
    "\n",
    "        if not G0:\n",
    "            nx.draw(G, pos, ax=ax, node_size=10, width=1.5, node_color='#d35400', alpha=0.7, edge_color='#34495e')\n",
    "        else:\n",
    "\n",
    "\n",
    "            nx.draw_networkx_edges(G, pos, edgelist=G0_edges, width=1.5, alpha=0.5, edge_color='#34495e', ax=ax)\n",
    "            nx.draw_networkx_edges(G, pos, edgelist=G_edges, width=1.5, alpha=1, edge_color='#e67e22', ax=ax)\n",
    "\n",
    "            nx.draw_networkx_nodes(G, pos, nodelist=list(G.nodes()), node_size=10, node_color=nodecolor, alpha=0.7, ax=ax)\n",
    "    else:\n",
    "        edge_color = {(u, v) : '#34495e' if (u, v) in G0_edges else '#e67e22'  for (u, v) in G.edges()}\n",
    "\n",
    "        netgraph.Graph(G, node_layout='spring', node_color=nodecolor, node_size=1.0, edge_color=edge_color, ax=ax)\n",
    "\n",
    "    ax.set_axis_off()\n",
    "\n",
    "def network_growth(T, n0, temperature, model, environment, role, cot, hash_and_shuffle, degrees, method='llm'):\n",
    "    G = nx.empty_graph(n0)\n",
    "\n",
    "    # G = nx.erdos_renyi_graph(n0, 0.5)\n",
    "\n",
    "    Gs = []\n",
    "    results = []\n",
    "\n",
    "    for t in range(n0, n0 + T):\n",
    "        print(f'Adding node {t}')\n",
    "        if t > 0:\n",
    "            if method == 'llm':\n",
    "                result = select_neighbor(G, t, temperature, degrees=degrees, model=model, environment=environment, role=role, cot=cot, hash_and_shuffle=hash_and_shuffle)\n",
    "            elif method == 'ba':\n",
    "                result = {'name' : random.choice(list(G.nodes(), weights=[G.degree(n) for n in G.nodes()]))}\n",
    "\n",
    "        G.add_node(t)\n",
    "        \n",
    "        if t > 0 and result:\n",
    "            v = result['name']\n",
    "            G.add_edge(t, v)\n",
    "\n",
    "        Gs.append(G.copy())\n",
    "        results.append(result)\n",
    "\n",
    "    return Gs, results\n",
    "\n",
    "def select_neighbor(G, t, temperature, model, environment, role, degrees, cot, hash_and_shuffle):\n",
    "    candidates = []\n",
    "    if hash_and_shuffle:\n",
    "        hash2idx = {}\n",
    "        idx2hash = {}\n",
    "\n",
    "        # sha256 hash of each node\n",
    "        for v in list(G.nodes()) + [0]:\n",
    "            h = str(hashlib.sha256(str(v).encode()).hexdigest())\n",
    "            hash2idx[h] = str(v)\n",
    "            idx2hash[str(v)] = h\n",
    "\n",
    "    for v in G.nodes():\n",
    "        if v != t:\n",
    "            if degrees:\n",
    "                candidates.append({'name' : v, 'number_of_friends' : G.degree(v)})\n",
    "            else:\n",
    "                nbrs = list(G.neighbors(v))\n",
    "                if hash_and_shuffle:\n",
    "                    nbrs = [idx2hash[str(n)] for n in nbrs]\n",
    "                    candidates.append({'name' : idx2hash[str(v)], 'friends' : nbrs})\n",
    "                else:\n",
    "                    candidates.append({'name' : v, 'friends' : nbrs})\n",
    "\n",
    "    # if len(candidates) > 200:\n",
    "    #     candidates = random.sample(candidates, 200)\n",
    "\n",
    "    if cot: \n",
    "        output_format = f\"\"\"\n",
    "    {{\n",
    "        \"reason\" : reason for selecting the person,\n",
    "        \"name\" : name of the person you selected\n",
    "    }}\n",
    "        \"\"\"\n",
    "    else:\n",
    "        output_format = f\"\"\"\n",
    "    {{\n",
    "        \"name\" : name of the person you selected,\n",
    "        \"reason\" : reason for selecting the person\n",
    "    }}\n",
    "        \"\"\"\n",
    "\n",
    "    preferential_attachment_prompt = f\"\"\"\n",
    "    # Task\n",
    "    {f'You are in a {environment}.' if environment else ''}Your task is to select a person to be {role} with.\n",
    "\n",
    "    # Input\n",
    "    The input is a list of dictionaries. \n",
    "    \n",
    "    The profiles are given below after chevrons:\n",
    "    \n",
    "    <PROFILES>\n",
    "    {json.dumps(candidates)}\n",
    "    </PROFILES>\n",
    "\n",
    "    # Output\n",
    "    The output should be given in JSON format with the following structure\n",
    "\n",
    "    {output_format}\n",
    "\n",
    "    # Notes\n",
    "\n",
    "    * The name of the person you selected must be one of the names in the input.\n",
    "    * Your output must be JSON only.\n",
    "\n",
    "    ```json\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(10):\n",
    "        ans = get_response(preferential_attachment_prompt, model, temperature=temperature)\n",
    "        try:\n",
    "            try:\n",
    "                result = json.loads(ans.split('```')[0])\n",
    "            except:\n",
    "                result = json.loads(ans.split('```json')[1].split('```')[0])\n",
    "\n",
    "            if not hash_and_shuffle and result['name'] in G.nodes():\n",
    "                print('NEW EDGE', result)\n",
    "                return result\n",
    "            elif hash_and_shuffle and result['name'] in hash2idx:\n",
    "                result['name'] = int(hash2idx[result['name']])\n",
    "                print('NEW EDGE', result)\n",
    "                return result\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n",
    "def run_network_formation_experiment(n_min, n_max, n_step, num_simulations, outfile, temperatures, environment=None, role='friends', degrees=True, model='gpt-3.5-turbo', cot=False, hash_and_shuffle=False):\n",
    "\n",
    "    saved_scenarios = set()\n",
    "\n",
    "    if os.path.exists(outfile):\n",
    "        with open(outfile) as f:\n",
    "            lines = f.read().splitlines()\n",
    "\n",
    "            for line in lines:\n",
    "                scenario = json.loads(line)\n",
    "                saved_scenarios.add((scenario['n'], scenario['simulation'], scenario['temperature']))\n",
    "\n",
    "        exit()\n",
    "\n",
    "    f = open(outfile, 'a+')\n",
    "\n",
    "    print(saved_scenarios)\n",
    "\n",
    "    for n in range(n_min, n_max + 1, n_step):\n",
    "        for i in range(num_simulations):\n",
    "            for temperature in temperatures:\n",
    "                if (n, i, temperature) in saved_scenarios:\n",
    "                    print(f'Skipping simulation for n={n}, i={i}, temperature={temperature}')\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f'Running simulation for n={n}, i={i}, temperature={temperature}')\n",
    "                    n0 = 1\n",
    "                    Gs, reasons = network_growth(n, n0, temperature=temperature, degrees=degrees, model=model, environment=environment, role=role, cot=cot, hash_and_shuffle=hash_and_shuffle)\n",
    "\n",
    "                    temp = {\n",
    "                        'n' : n,\n",
    "                        'n0' : n0,\n",
    "                        'temperature' : temperature,\n",
    "                        'simulation' : i,\n",
    "                        'graphs' : [nx.to_dict_of_lists(G) for G in Gs],\n",
    "                        'reasons' : reasons\n",
    "                    }    \n",
    "\n",
    "                    f.write(json.dumps(temp) + '\\n')            \n",
    "\n",
    "    f.close()\n",
    "\n",
    "def analyze_experiments(filename, dgr=True):\n",
    "\n",
    "    suffix = os.path.split(os.path.splitext(filename)[0])[-1]\n",
    "\n",
    "    palette = ['#e67e22', '#f1c40f', '#3498db', '#7f8c8d', '#c0392b', '#34495e', '#2980b9']\n",
    "\n",
    "    with open(filename) as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for line in lines:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "    degree_freqs = collections.defaultdict(list)\n",
    "    dergee_freqs_barabasi_albert = collections.defaultdict(list)\n",
    "\n",
    "    wasserstein_distances = collections.defaultdict(list)\n",
    "    ks_statistics = collections.defaultdict(list)\n",
    "    gammas = collections.defaultdict(list)\n",
    "    gammas_barabasi_albert = collections.defaultdict(list)\n",
    "    sigmas = collections.defaultdict(list)\n",
    "    sigmas_barabasi_albert = collections.defaultdict(list)\n",
    "    ks_powerlaw = collections.defaultdict(list)\n",
    "    confidence_ks_intervals = collections.defaultdict(list)\n",
    "    pwl_fits = collections.defaultdict(list)\n",
    "    pwl_fits_barabasi_albert = collections.defaultdict(list)\n",
    "\n",
    "    final_graphs = collections.defaultdict(list)\n",
    "\n",
    "    for d in data:\n",
    "        Gs = []\n",
    "        for graph in d['graphs']:\n",
    "            G = nx.Graph()\n",
    "\n",
    "            for k, v in graph.items():\n",
    "                k = int(k)\n",
    "                G.add_node(k)\n",
    "                for n in v:\n",
    "                    G.add_edge(k, n)\n",
    "\n",
    "            G.remove_nodes_from(list(nx.isolates(G)))\n",
    "            Gs.append(G)\n",
    "\n",
    "        final_graphs[d['n'], d['temperature']].append((Gs[-1].copy(), Gs[0].copy()))\n",
    "\n",
    "        fig, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
    "        fig_barabasi_albert, ax_barabasi_albert = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "        # fig.suptitle(f'Graph created based on Principle 1 with $n = {d[\"n\"]}$, $n_0 = {d[\"n0\"]}$, temperature = {d[\"temperature\"]}')\n",
    "\n",
    "        G_barabasi_albert = nx.barabasi_albert_graph(n=d['n'], m=1, seed=1)\n",
    "\n",
    "        for i, t in enumerate([len(Gs) // 3, 2 * len(Gs) // 3, len(Gs) - 1]):\n",
    "            G = Gs[t]\n",
    "            ax[i].set_title(f'$t = {t}$')\n",
    "            if len(Gs[0]) > 2:\n",
    "                draw_graph(G, ax=ax[i], G0=Gs[0])\n",
    "            else:\n",
    "                draw_graph(G, ax=ax[i])\n",
    "            \n",
    "        draw_graph(G_barabasi_albert, ax=ax_barabasi_albert[0], nodecolor='#3498db')\n",
    "\n",
    "\n",
    "        degrees = [G.degree(n) for n in G.nodes()]\n",
    "        degrees_barabasi_albert = [G_barabasi_albert.degree(n) for n in G_barabasi_albert.nodes()]\n",
    "\n",
    "        powerlaw_fit = pwl.Fit(degrees, discrete=True)\n",
    "\n",
    "        print(f'Temperature {d[\"temperature\"]}: xmin: {powerlaw_fit.xmin}, alpha: {powerlaw_fit.alpha}, sigma: {powerlaw_fit.sigma}')\n",
    "\n",
    "        powerlaw_fit_barabasi_albert = pwl.Fit(degrees_barabasi_albert, discrete=True)\n",
    "\n",
    "        wasserstein_distances[d['n'], d['temperature']].append(stats.wasserstein_distance(degrees, degrees_barabasi_albert))\n",
    "        gammas[d['n'], d['temperature']].append(powerlaw_fit.alpha)\n",
    "        sigmas[d['n'], d['temperature']].append(powerlaw_fit.sigma)\n",
    "\n",
    "        gammas_barabasi_albert[d['n'], d['temperature']].append(powerlaw_fit_barabasi_albert.alpha)\n",
    "        sigmas_barabasi_albert[d['n'], d['temperature']].append(powerlaw_fit_barabasi_albert.sigma)\n",
    "\n",
    "        ks_powerlaw[d['n'], d['temperature']].append(powerlaw_fit.power_law.KS(degrees))\n",
    "\n",
    "        ax[-1].set_title('Degree distribution')\n",
    "        ax[-1].spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "        ax_barabasi_albert[-1].set_title('Degree distribution')\n",
    "\n",
    "        powerlaw_fit.plot_ccdf(linewidth=3, ax=ax[-1], color='#e74c3c', label='LLM (Empirical)')\n",
    "        powerlaw_fit_barabasi_albert.plot_ccdf(linewidth=3, ax=ax[-1], color='#3498db', label='BA (Empirical)')\n",
    "\n",
    "        powerlaw_fit_barabasi_albert.plot_ccdf(linewidth=3, ax=ax_barabasi_albert[-1], color='#3498db', label='BA (Empirical)')\n",
    "\n",
    "        powerlaw_fit.power_law.plot_ccdf(ax=ax[-1], color='#e74c3c', linestyle='--', label='LLM (Power law fit)')\n",
    "        powerlaw_fit_barabasi_albert.power_law.plot_ccdf(ax=ax[-1], color='#3498db', linestyle='--', label='BA (Power law fit)')\n",
    "\n",
    "        powerlaw_fit_barabasi_albert.power_law.plot_ccdf(ax=ax_barabasi_albert[-1], color='#3498db', linestyle='--', label='BA (Power law fit)')\n",
    "\n",
    "        print(f'BA powerlaw fit gamma: {powerlaw_fit_barabasi_albert.power_law.alpha:.2f} +- {powerlaw_fit_barabasi_albert.power_law.sigma:.2f}')\n",
    "\n",
    "        pwl_fits[d['n'], d['temperature']].append(powerlaw_fit)\n",
    "        pwl_fits_barabasi_albert[d['n'], d['temperature']].append(powerlaw_fit_barabasi_albert)\n",
    "\n",
    "        print(f'Temperature: {d[\"temperature\"]}, KS Test with BA (empirical): {stats.ks_2samp(degrees, degrees_barabasi_albert)}')\n",
    "        print()\n",
    "      \n",
    "        # Exports to perform bootstrap hypothesis test in R using the poweRlaw package\n",
    "        df = pd.DataFrame(degrees)\n",
    "        df.to_csv(f'degrees{\"_neighbors\" if not dgr else \"\"}_{d[\"n\"]}_{d[\"simulation\"]}_{d[\"temperature\"]}.txt', header=None, index=False)\n",
    "\n",
    "        ax[-1].legend()\n",
    "        ax[-1].set_xlabel('Degree')\n",
    "        ax[-1].set_ylabel('CCDF')\n",
    "        ax[-1].spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "\n",
    "        ax_barabasi_albert[-1].legend()\n",
    "        ax_barabasi_albert[-1].set_xlabel('Degree')\n",
    "        ax_barabasi_albert[-1].set_ylabel('CCDF')\n",
    "\n",
    "        fig.tight_layout()\n",
    "\n",
    "        fig.suptitle(f'Temperature = {d[\"temperature\"]}', y=1.05)\n",
    "        fig_barabasi_albert.suptitle('BA Model', y=1.05)\n",
    "\n",
    "        fig.savefig(f'figures/principle_1/{suffix}_{d[\"n\"]}_{d[\"simulation\"]}_{d[\"temperature\"]}{\"_neighbors\" if not dgr else \"\"}.png', dpi=300, bbox_inches='tight')\n",
    "        fig_barabasi_albert.savefig(f'figures/principle_1/{suffix}_{d[\"n\"]}_{d[\"simulation\"]}_{d[\"temperature\"]}_barabasi_albert{\"_neighbors\" if not dgr else \"\"}.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1 + len(final_graphs), figsize=(5 * (1 + len(final_graphs)), 5), squeeze=False, gridspec_kw={'width_ratios': [1] * (1 + len(final_graphs))})\n",
    "    # fig.suptitle(f'Graphs created based on Principle 1 with $n = {d[\"n\"]}$, $n_0={d[\"n0\"]}$')\n",
    "\n",
    "    for i, k in enumerate(sorted(final_graphs.keys())):\n",
    "        G, G0 = final_graphs[k][0]\n",
    "        \n",
    "        if len(G0) > 2:\n",
    "            draw_graph(G, ax[0, i], G0=G0, nodecolor=palette[i])\n",
    "        else:\n",
    "            draw_graph(G, ax[0, i], nodecolor=palette[i])\n",
    "        ax[0, i].set_title(f'Temperature = {k[-1]}')\n",
    "\n",
    "\n",
    "    for i, k in enumerate(sorted(pwl_fits.keys())):\n",
    "        powerlaw_fit = pwl_fits[k][0]\n",
    "        powerlaw_fit.plot_ccdf(linewidth=3, ax=ax[0, -1], color=palette[i], label=str(k[-1]))\n",
    "        powerlaw_fit.power_law.plot_ccdf(ax=ax[0, -1], color=palette[i], linestyle='--')\n",
    "    \n",
    "\n",
    "    for i, k in enumerate(sorted(pwl_fits.keys())):\n",
    "\n",
    "        powerlaw_fit_barabasi_albert = pwl_fits_barabasi_albert[k][0]\n",
    "\n",
    "        if i == 0:\n",
    "            powerlaw_fit_barabasi_albert.plot_ccdf(linewidth=3, ax=ax[0, -1], color='#7f8c8d', label='BA')\n",
    "            powerlaw_fit_barabasi_albert.power_law.plot_ccdf(ax=ax[0, -1], color='#7f8c8d', linestyle='--')\n",
    "\n",
    "\n",
    "    ax[0, -1].legend()\n",
    "    ax[0, -1].set_xlabel('Degree')\n",
    "    ax[0, -1].set_ylabel('Complementary CDF')\n",
    "    ax[0, -1].spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig.savefig(f'figures/principle_1/{suffix}_final_graphs{\"_neighbors\" if not dgr else \"\"}.png', dpi=300)\n",
    "\n",
    "\n",
    "def analyze_experiments_multiple_llms(filenames, sfx=''):\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for filename in filenames:\n",
    "        suffix = os.path.split(os.path.splitext(filename)[0])[-1]\n",
    "        suffix = suffix.split('+')\n",
    "        \n",
    "        with open(filename) as f:\n",
    "            lines = f.read().splitlines()\n",
    "\n",
    "        data = []\n",
    "\n",
    "        for line in lines:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "        for d in data:\n",
    "            Gs = []\n",
    "            for graph in d['graphs']:\n",
    "                G = nx.Graph()\n",
    "\n",
    "                for k, v in graph.items():\n",
    "                    k = int(k)\n",
    "                    G.add_node(k)\n",
    "                    for n in v:\n",
    "                        G.add_edge(k, n)\n",
    "\n",
    "                G.remove_nodes_from(list(nx.isolates(G)))\n",
    "                Gs.append(G)\n",
    "\n",
    "            G_barabasi_albert = nx.barabasi_albert_graph(n=d['n'], m=1, seed=1)\n",
    "\n",
    "            G = Gs[-1]\n",
    "\n",
    "            degrees = np.array([G.degree(n) for n in G.nodes()])\n",
    "            degrees_barabasi_albert = np.array([G_barabasi_albert.degree(n) for n in G_barabasi_albert.nodes()])\n",
    "\n",
    "\n",
    "            powerlaw_fit = pwl.Fit(degrees, discrete=True)\n",
    "\n",
    "            wasserstein_distance = stats.wasserstein_distance(degrees, degrees_barabasi_albert)\n",
    "            gamma = powerlaw_fit.alpha\n",
    "            sigma = powerlaw_fit.sigma\n",
    "\n",
    "            if len(suffix) == 3:\n",
    "                model = suffix[-2]\n",
    "                environment = suffix[-1]\n",
    "            elif len(suffix) == 2:\n",
    "                model = suffix[-1]\n",
    "                environment = 'Baseline'\n",
    "            else:\n",
    "                environment = 'Baseline'\n",
    "\n",
    "            ks_stats = stats.ks_2samp(degrees, degrees_barabasi_albert)\n",
    "\n",
    "            if ks_stats[1] < 0.001:\n",
    "                stars = '***'\n",
    "            elif ks_stats[1] < 0.01:\n",
    "                stars = '**'\n",
    "            elif ks_stats[1] < 0.05:\n",
    "                stars = '*'\n",
    "            else:\n",
    "                stars = 'p = {:.3f}'.format(ks_stats[1])\n",
    "\n",
    "\n",
    "            # top k plot info\n",
    "\n",
    "            degrees = np.sort(degrees)[::-1]\n",
    "\n",
    "            # insert 0 at the beginning\n",
    "            degrees = np.insert(degrees, 0, 0)\n",
    "            degrees_cumsum = np.cumsum(degrees)\n",
    "            probability_of_topk_yaxis = degrees_cumsum / degrees_cumsum[-1]\n",
    "\n",
    "            probability_of_topk_xaxis = np.arange(len(degrees)) / len(degrees)\n",
    "        \n",
    "            record = {\n",
    "                'Model' : model,\n",
    "                'Environment' : environment,\n",
    "                'Temperature' : d['temperature'],\n",
    "                '$\\\\hat \\\\gamma$' : gamma,\n",
    "                '$\\\\sigma$' : sigma,\n",
    "                'KS Test' : f'{ks_stats[0]:.3f} ({stars})',\n",
    "                'Probability of Connecting to Top-$k$' : probability_of_topk_yaxis,\n",
    "                'Top-$k$' : probability_of_topk_xaxis\n",
    "            }\n",
    "\n",
    "            records.append(record)\n",
    "\n",
    "    G_barabasi_albert = nx.barabasi_albert_graph(n=d['n'], m=1, seed=1)\n",
    "    degrees_barabasi_albert = [G_barabasi_albert.degree(n) for n in G_barabasi_albert.nodes()]\n",
    "    powerlaw_fit = pwl.Fit(degrees_barabasi_albert, discrete=True)\n",
    "    gamma = powerlaw_fit.alpha\n",
    "    sigma = powerlaw_fit.sigma\n",
    "\n",
    "    record = {\n",
    "        'Model' : 'Barabasi-Albert',\n",
    "        'Environment' : 'Baseline',\n",
    "        'Temperature' : None,\n",
    "        '$\\\\hat \\\\gamma$' : gamma,\n",
    "        '$\\\\sigma$' : sigma,\n",
    "        'KS Test' : None\n",
    "    }\n",
    "\n",
    "    records.append(record)\n",
    "\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "\n",
    "\n",
    "    df.to_csv('tables/exponents.csv', index=False)\n",
    "    df.to_latex('tables/exponents.tex', index=False, escape=False, float_format=\"%.3f\")\n",
    "\n",
    "    rename_models = {\n",
    "        'gpt-3.5-turbo' : 'GPT-3.5',\n",
    "        'gpt-4o-mini' : 'GPT-4 Mini',\n",
    "        'meta-meta-llama-3-70b-instruct' : 'LLAMA-3',\n",
    "        'meta-meta-llama-3-8b-instruct' : 'LLAMA-3-8b',\n",
    "        'claude-3-5-sonnet-20240620' : 'Claude 3.5',\n",
    "        'gpt-3.5-turbo_cot' : 'GPT-3.5',\n",
    "        'gpt-4o-mini_cot' : 'GPT-4 Mini',\n",
    "        'meta-meta-llama-3-70b-instruct_cot' : 'LLAMA-3',\n",
    "        'meta-meta-llama-3-8b-instruct_cot' : 'LLAMA-3',\n",
    "\n",
    "        'claude-3-5-sonnet-20240620_cot' : 'Claude 3.5',\n",
    "    }\n",
    "\n",
    "    rename_environment = {\n",
    "        'school' : 'School',\n",
    "        'community' : 'Community',\n",
    "        'work' : 'Work',\n",
    "        'school_cot' : 'School',\n",
    "        'community_cot' : 'Community',\n",
    "        'work_cot' : 'Work'\n",
    "    }\n",
    "\n",
    "\n",
    "    df['Model'] = df['Model'].apply(lambda x: rename_models.get(x, x))\n",
    "    df['Environment'] = df['Environment'].apply(lambda x: rename_environment.get(x, x))\n",
    "\n",
    "\n",
    "    df_model = df.query('Environment == \"Baseline\" and Temperature == 1.0')\n",
    "    df_model = df_model[df_model['Model'] != 'Barabasi-Albert']\n",
    "\n",
    "    df_environment = df.query('Model == \"GPT-3.5\" and Temperature == 1.5')\n",
    "    df_temperature = df.query('Model == \"GPT-3.5\" and Environment == \"Baseline\"')\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    sc_model = sns.barplot(data=df_model, y='$\\\\hat \\\\gamma$', x='Model', ax=ax[0], palette=['#e67e22', '#f1c40f', '#3498db', '#7f8c8d', '#c0392b', '#34495e', '#2980b9'])\n",
    "    sc_temperature = sns.barplot(data=df_temperature, y='$\\\\hat \\\\gamma$', x='Temperature', ax=ax[1], palette=['#e67e22', '#f1c40f', '#3498db', '#7f8c8d', '#c0392b', '#34495e', '#2980b9'])\n",
    "    sc_environment = sns.barplot(data=df_environment, y='$\\\\hat \\\\gamma$', x='Environment', ax=ax[2], palette=['#e67e22', '#f1c40f', '#3498db', '#7f8c8d', '#c0392b', '#34495e', '#2980b9'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    sc_model.set_xticklabels(sc_model.get_xticklabels(), rotation=90)\n",
    "    sc_temperature.set_xticklabels(sc_temperature.get_xticklabels(), rotation=90)\n",
    "    sc_environment.set_xticklabels(sc_environment.get_xticklabels(), rotation=90)\n",
    "\n",
    "    ax[0].errorbar(df_model['Model'], df_model['$\\\\hat \\\\gamma$'], yerr=df_model['$\\\\sigma$'], color='black', linestyle='', capsize=10, alpha=0.5)\n",
    "    ax[1].errorbar(['0.5', '1.0', '1.5'], df_temperature['$\\\\hat \\\\gamma$'], yerr=df_temperature['$\\\\sigma$'], color='black', linestyle='', capsize=10, alpha=0.5)\n",
    "    ax[2].errorbar(df_environment['Environment'], df_environment['$\\\\hat \\\\gamma$'], yerr=df_environment['$\\\\sigma$'], color='black', linestyle='', capsize=10, alpha=0.5)\n",
    "\n",
    "\n",
    "\n",
    "    gamma_ba = df[df['Model'] == 'Barabasi-Albert']['$\\\\hat \\\\gamma$'].values[0]\n",
    "    sigma_ba = df[df['Model'] == 'Barabasi-Albert']['$\\\\sigma$'].values[0]\n",
    "\n",
    "    # draw baraasi-albert line\n",
    "    ax[0].axhline(y=gamma_ba, color='#c0392b', linestyle='--', label='BA (Sample)', linewidth=3)\n",
    "    ax[1].axhline(y=gamma_ba, color='#c0392b', linestyle='--', label='BA (Sample)', linewidth=3)\n",
    "    ax[2].axhline(y=gamma_ba, color='#c0392b', linestyle='--', label='BA (Sample)', linewidth=3)\n",
    "\n",
    "    ax[0].axhline(y=3, color='#34495e', linestyle=':', label='BA (Theoretical)', linewidth=3)\n",
    "    ax[1].axhline(y=3, color='#34495e', linestyle=':', label='BA (Theoretical)', linewidth=3)\n",
    "    ax[2].axhline(y=3, color='#34495e', linestyle=':', label='BA (Theoretical)', linewidth=3)\n",
    "\n",
    "    ax[0].legend(fontsize=0.7*SMALL_SIZE)\n",
    "\n",
    "    ax[0].set_ylim(1, 5)\n",
    "    ax[1].set_ylim(1, 5)\n",
    "    ax[2].set_ylim(1, 5)\n",
    "\n",
    "    ax[1].set_ylabel('')\n",
    "    ax[2].set_ylabel('')\n",
    "\n",
    "    ax[0].set_xlabel('')\n",
    "    ax[1].set_xlabel('')\n",
    "    ax[2].set_xlabel('')\n",
    "\n",
    "    ax[0].set_title('Model')\n",
    "    ax[1].set_title('Temperature')\n",
    "    ax[2].set_title('Environment')\n",
    "\n",
    "\n",
    "    ax[1].get_yaxis().set_visible(False)\n",
    "    ax[2].get_yaxis().set_visible(False)\n",
    "\n",
    "    ax[0].spines[['right', 'top']].set_visible(False)\n",
    "    ax[1].spines[['right', 'top']].set_visible(False)\n",
    "    ax[2].spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "    # fig.tight_layout()\n",
    "\n",
    "    fig.savefig(f'figures/exponents{sfx}.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # plot probability of connecting to top-k\n",
    "\n",
    "    palette=['#e67e22', '#f1c40f', '#3498db', '#7f8c8d', '#c0392b', '#34495e', '#2980b9']\n",
    "\n",
    "\n",
    "\n",
    "    breakpoints_arr = [('top', np.array([0.01, 0.015, 0.02, 0.025])), ('all', np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99]))]\n",
    "\n",
    "    for label, breakpoints in breakpoints_arr:\n",
    "\n",
    "        breakpoint_max = np.max(breakpoints)\n",
    "        breakpoint_min = np.min(breakpoints)\n",
    "\n",
    "        fig.suptitle('Probability of Connecting to Top-$k$ Degrees', fontsize=SMALL_SIZE)\n",
    "\n",
    "        for i in range(len(ax)):\n",
    "            ax[i].plot([0, 100 * breakpoint_max], [0, breakpoint_max], color='black', linestyle='--')\n",
    "            ax[i].set_xlim(100 * breakpoint_min, 100 * breakpoint_max)\n",
    "\n",
    "        for i, model in enumerate(df_model['Model']):\n",
    "            n = len(df_model['Top-$k$'].values[i])\n",
    "            indices = np.array([int(x * n) for x in breakpoints])\n",
    "            jitter = np.random.uniform(0, 0.1) * np.ones(len(indices))\n",
    "\n",
    "            color = palette[i]\n",
    "            linewidth = 1\n",
    "\n",
    "            if model == 'GPT-3.5' and df_model['Environment'].values[i] == 'Baseline' and df_model['Temperature'].values[i] == 1.0:\n",
    "                color = '#34495e'\n",
    "                linewidth = 3\n",
    "            \n",
    "            ax[0].plot(100 * df_model['Top-$k$'].values[i][indices] + jitter, df_model['Probability of Connecting to Top-$k$'].values[i][indices] + jitter, label=model, color=color, linewidth=linewidth, marker='x')\n",
    "\n",
    "        ax[0].set_title('Model')\n",
    "        ax[0].set_xlabel('Top-$k$ (%)')\n",
    "        # ax[0].set_xscale('log')\n",
    "        # ax[0].set_yscale('log')\n",
    "        ax[0].set_ylabel('')\n",
    "        \n",
    "        ax[0].legend(fontsize=0.7*SMALL_SIZE, ncol=2)\n",
    "\n",
    "        for i, temperature in enumerate(df_temperature['Temperature']):\n",
    "            n = len(df_model['Top-$k$'].values[i])\n",
    "            indices = np.array([int(x * n) for x in breakpoints])\n",
    "\n",
    "            color = palette[i]\n",
    "\n",
    "            color = palette[i]\n",
    "            linewidth = 1\n",
    "\n",
    "            if temperature == 1.5 and df_temperature['Model'].values[i] == 'GPT-3.5' and df_temperature['Environment'].values[i] == 'Baseline':\n",
    "                color = '#34495e'\n",
    "                linewidth = 3\n",
    "\n",
    "            ax[1].plot(100 * df_temperature['Top-$k$'].values[i][indices], df_temperature['Probability of Connecting to Top-$k$'].values[i][indices], label=f'{temperature}', color=color, linewidth=linewidth, marker='x')\n",
    "\n",
    "        ax[1].set_title('Temperature')\n",
    "        ax[1].set_xlabel('Top-$k$ (%)')\n",
    "        # ax[1].set_xscale('log')\n",
    "        # ax[1].set_yscale('log')\n",
    "        ax[1].set_ylabel('')\n",
    "\n",
    "        ax[1].legend(fontsize=0.7*SMALL_SIZE)\n",
    "\n",
    "        for i, environment in enumerate(df_environment['Environment']):\n",
    "            n = len(df_model['Top-$k$'].values[i])\n",
    "            indices = np.array([int(x * n) for x in breakpoints])\n",
    "\n",
    "            color = palette[i]\n",
    "            linewidth = 1\n",
    "\n",
    "            if environment == 'Baseline' and df_environment['Model'].values[i] == 'GPT-3.5' and df_environment['Temperature'].values[i] == 1.5:\n",
    "                color = '#34495e'\n",
    "                linewidth = 3\n",
    "\n",
    "            ax[2].plot(100 * df_environment['Top-$k$'].values[i][indices], df_environment['Probability of Connecting to Top-$k$'].values[i][indices], label=environment, color=color, linewidth=linewidth, marker='x')\n",
    "\n",
    "        ax[2].set_title('Environment')\n",
    "        ax[2].set_xlabel('Top-$k$ (%)')\n",
    "        # ax[2].set_xscale('log')\n",
    "        # ax[2].set_yscale('log')\n",
    "        ax[2].set_ylabel('')\n",
    "\n",
    "        ax[2].legend(fontsize=0.7*SMALL_SIZE, ncols=2)\n",
    "\n",
    "        ax[0].set_ylim(0, 1)\n",
    "        ax[1].set_ylim(0, 1)\n",
    "        ax[2].set_ylim(0, 1)\n",
    "\n",
    "        # hide y axis numbers\n",
    "        ax[1].get_yaxis().set_visible(False)\n",
    "        ax[2].get_yaxis().set_visible(False)\n",
    "\n",
    "        ax[0].spines[['right', 'top']].set_visible(False)\n",
    "        ax[1].spines[['right', 'top']].set_visible(False)\n",
    "        ax[2].spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "        fig.tight_layout()\n",
    "\n",
    "        fig.savefig(f'figures/probabilitytopk_{label}_{sfx}.png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Formation Experiments\n",
    "\n",
    "### Without Chain-of-Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponents_outfiles = []\n",
    "\n",
    "# Other environments\n",
    "for environment, role in zip(['school', 'work', 'community'], ['classmates', 'colleagues', 'neighbors']):\n",
    "    outfile = f'outputs/principle_1_neighbors+gpt-3.5-turbo+{environment}.jsonl'\n",
    "    run_network_formation_experiment(200, 200, 1, 1, outfile, [1.5], environment=environment, role=role, degrees=False)\n",
    "\n",
    "    exponents_outfiles.append(outfile)\n",
    "\n",
    "# Other models\n",
    "for model in ['gpt-3.5-turbo', 'meta/meta-llama-3-70b-instruct', 'gpt-4o-mini', 'claude-3-5-sonnet-20240620']:\n",
    "    outfile = f'outputs/principle_1_neighbors+{model.replace(\"/\", \"-\")}.jsonl'\n",
    "    if model == 'claude-3-5-sonnet-20240620':\n",
    "        run_network_formation_experiment(200, 200, 1, 1, outfile, [0.5, 1.0], degrees=False, model=model)\n",
    "    else:\n",
    "        run_network_formation_experiment(200, 200, 1, 1, outfile, [0.5, 1.0, 1.5], degrees=False, model=model)\n",
    "    \n",
    "    if model == 'gpt-4o-mini':\n",
    "        analyze_experiments(outfile, dgr=False)\n",
    "\n",
    "    exponents_outfiles.append(outfile)\n",
    "\n",
    "analyze_experiments_multiple_llms(exponents_outfiles)\n",
    "\n",
    "run_network_formation_experiment(200, 200, 1, 1, 'outputs/principle_1+gpt-3.5-turbo.jsonl', [0.5, 1.0, 1.5], degrees=True)\n",
    "# analyze_experiments('outputs/principle_1+gpt-3.5-turbo.jsonl', dgr=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Chain-of-Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponents_outfiles_cot = []\n",
    "\n",
    "for environment, role in zip(['school', 'work', 'community'], ['classmates', 'colleagues', 'neighbors']):\n",
    "    outfile = f'outputs/principle_1_neighbors+gpt-3.5-turbo+{environment}_cot.jsonl'\n",
    "    run_network_formation_experiment(200, 200, 1, 1, outfile, [1.5], environment=environment, role=role, degrees=False, cot=True)\n",
    "\n",
    "    exponents_outfiles_cot.append(outfile)\n",
    "\n",
    "# Other models\n",
    "for model in ['gpt-3.5-turbo', 'gpt-4o-mini', 'claude-3-5-sonnet-20240620', 'meta/meta-llama-3-70b-instruct']:\n",
    "    outfile = f'outputs/principle_1_neighbors+{model.replace(\"/\", \"-\")}_cot.jsonl'\n",
    "    \n",
    "    if model == 'claude-3-5-sonnet-20240620':\n",
    "        run_network_formation_experiment(200, 200, 1, 1, outfile, [0.5, 1.0], degrees=False, model=model, cot=True)\n",
    "    else:\n",
    "        run_network_formation_experiment(200, 200, 1, 1, outfile, [0.5, 1.0, 1.5], degrees=False, model=model, cot=True)\n",
    "    \n",
    "    exponents_outfiles_cot.append(outfile)\n",
    "\n",
    "analyze_experiments_multiple_llms(exponents_outfiles_cot, sfx='_cot')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
