{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import openai\n",
    "import random\n",
    "import os\n",
    "import collections\n",
    "import copy\n",
    "import netgraph\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "\n",
    "MEDIUM_SIZE = 18\n",
    "SMALL_SIZE = 0.85 * MEDIUM_SIZE\n",
    "BIGGER_SIZE = 1.5 * MEDIUM_SIZE\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "with open('params.json') as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "openai.api_key = params['OPENAI_API_KEY']\n",
    "openai.organization = params['OPENAI_ORG']\n",
    "\n",
    "\n",
    "def get_response(prompt, model='gpt-3.5-turbo', temperature=0.9, system_prompt=\"You are mimicking a real-life person who wants to make friends.\"):\n",
    "    result = openai.ChatCompletion.create(\n",
    "    model=model,\n",
    "    temperature=temperature,\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "    ])\n",
    "\n",
    "    return result.choices[0]['message']['content']\n",
    "\n",
    "    \n",
    "def summarize_reasons(filename, n_samples=20, n_categories=4, n_resamples=5, categories=None):\n",
    "    random.seed(1)\n",
    "    np.random.seed(1)\n",
    "\n",
    "    with open(filename) as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for line in lines:\n",
    "\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "    reason_list = collections.defaultdict(list)\n",
    "\n",
    "    all_reasons = []\n",
    "\n",
    "    for d in data:        \n",
    "        for result in d[\"reasons\"]:\n",
    "            if result and 'reason' in result.keys():\n",
    "                reason_list[d['temperature']].append(result['reason'])\n",
    "                all_reasons.append(result['reason'])\n",
    "    if categories is None:\n",
    "        categorization_prompt = f\"\"\"\n",
    "        # Task\n",
    "\n",
    "        You are given a list of reasons and your task to find {n_categories} categories that best describe the reasons.\n",
    "\n",
    "        # Input\n",
    "\n",
    "        The input is a list of reasons. The list is given below after chevrons:\n",
    "        <REASONS>\n",
    "        {json.dumps(random.sample(all_reasons, len(reason_list) * n_samples))}\n",
    "        </REASONS>\n",
    "\n",
    "        # Output\n",
    "\n",
    "        The output should be given in JSON format with the following structure:\n",
    "\n",
    "        [\n",
    "            {{\n",
    "                \"category\" : category,\n",
    "                \"description\" : short description of the category\n",
    "            }}, ...\n",
    "        ]\n",
    "\n",
    "        # Notes\n",
    "        * The names of the categories must be descriptive and mutually exclusive.\n",
    "\n",
    "        ```json\n",
    "        \"\"\"\n",
    "\n",
    "        for _ in range(10):\n",
    "            try:\n",
    "                ans = get_response(categorization_prompt, temperature=0, system_prompt=\"You are a helpful assistant\")\n",
    "                categories = json.loads(ans.split('```')[0])\n",
    "                print(categories)\n",
    "                break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "    category_list = [c['category'] for c in categories]\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for i, (k, v) in enumerate(reason_list.items()):\n",
    "        print('Temperature', k)\n",
    "        if len(v) <= n_samples:\n",
    "            n_resamples = 1\n",
    "\n",
    "        for r in range(n_resamples):\n",
    "            prompt = f\"\"\"\n",
    "            # Task\n",
    "            You are given a list of reasons and your task is to classify them into categories.\n",
    "\n",
    "            # Input\n",
    "            The input is a list of reasons. The list is given below after chevrons:\n",
    "            <REASONS>\n",
    "            {json.dumps(random.sample(v, n_samples), indent=4)}\n",
    "            </REASONS>\n",
    "\n",
    "            ## Categories\n",
    "            The names of the categories are given below after chevrons:\n",
    "            <CATEGORIES>\n",
    "            {json.dumps(categories, indent=4)}\n",
    "            </CATEGORIES>\n",
    "\n",
    "            Each reason must be assigned to exactly one of the categories.\n",
    "            \n",
    "            # Output\n",
    "            The output should be given as a list of JSON objects with the following structure:\n",
    "\n",
    "            [\n",
    "                {{\n",
    "                        \"reason\" : reason,\n",
    "                        \"category\" : category name\n",
    "                }}, ...\n",
    "            ]\n",
    "\n",
    "            ```json\n",
    "            \"\"\"\n",
    "\n",
    "            for _ in range(10):\n",
    "                try:\n",
    "                    ans = get_response(prompt, temperature=0, system_prompt=\"You are a helpful assistant\")\n",
    "\n",
    "                    result = json.loads(ans.split('```')[0])\n",
    "\n",
    "                    assert(isinstance(result, list))\n",
    "\n",
    "                    reason_types = collections.defaultdict(float)\n",
    "\n",
    "                    total = 0\n",
    "\n",
    "                    for reason in result:\n",
    "                        if reason['category'] in category_list:\n",
    "                            reason_types[reason['category']] += 1\n",
    "                            total += 1\n",
    "\n",
    "                    for key, val in reason_types.items():\n",
    "                        reason_types[key] = val / total * 100\n",
    "\n",
    "                   \n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "\n",
    "            for key, val in reason_types.items():\n",
    "                records.append({\n",
    "                    'Temperature' : k,\n",
    "                    'Category' : key,\n",
    "                    'Frequency' : val,\n",
    "                    'Resample' : r\n",
    "                })\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame.from_records(records)\n",
    "\n",
    "    fig.suptitle('Reasoning for Principle 5', fontsize=MEDIUM_SIZE)\n",
    "\n",
    "    sns.barplot(data=df, x='Category', y='Frequency', hue='Temperature', ax=ax, palette='Set2')\n",
    "\n",
    "    plt.legend(fontsize=0.75*SMALL_SIZE, title='Temperature')\n",
    "\n",
    "    plt.xticks(rotation=0, fontsize=0.75*SMALL_SIZE)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig.savefig(f'figures/principle_5/principle_5_reasons.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "def print_reasons(filename):\n",
    "    with open(filename) as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for line in lines:\n",
    "\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "    for d in data:\n",
    "        if d[\"n\"] == 50 and d[\"simulation\"] == 0:\n",
    "            print(f'n = {d[\"n\"]}, simulation = {d[\"simulation\"]}, temperature = {d[\"temperature\"]}')\n",
    "            print(d['reasons'])\n",
    "\n",
    "def barrat_weight_clustering_coefficient(G):\n",
    "\n",
    "    triangles = 0\n",
    "    triples = 0\n",
    "\n",
    "    for node in G.nodes():\n",
    "        for neighbor in G.neighbors(node):\n",
    "            for neighbor2 in G.neighbors(neighbor):\n",
    "                if neighbor2 in G.neighbors(node):\n",
    "                    triangles += 1\n",
    "\n",
    "                triples += 1\n",
    "\n",
    "    return triangles / triples\n",
    "\n",
    "def fit_beta_ws(G, k, method='binary_search', tol=0.01):\n",
    "    if method == 'closed_form':\n",
    "        C = barrat_weight_clustering_coefficient(G)\n",
    "        C0 = 3 * (k - 1) / (2 * (2 * k - 1))\n",
    "        return 1 - (C / C0)**(1 / 3)\n",
    "    \n",
    "    elif method == 'binary_search':\n",
    "\n",
    "        beta_max = 1\n",
    "        beta_min = 0.01\n",
    "\n",
    "        n = len(G)\n",
    "\n",
    "        C = nx.average_clustering(G)\n",
    "\n",
    "\n",
    "        while True:\n",
    "            beta = (beta_max + beta_min) / 2\n",
    "\n",
    "            Gs_WS, _ = network_growth(n, k, beta, 0, method='W-S')\n",
    "            G_WS = Gs_WS[-1]\n",
    "\n",
    "            C_WS = nx.average_clustering(G_WS)\n",
    "\n",
    "            if abs(C_WS - C) < tol:\n",
    "                return beta\n",
    "            elif C_WS < C:\n",
    "                beta_max = beta\n",
    "            else:\n",
    "                beta_min = beta\n",
    "\n",
    "        return beta\n",
    "\n",
    "                \n",
    "def network_growth(n, k, beta, temperature, method='llm'):\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Create ring network\n",
    "    for i in range(n):\n",
    "        G.add_node(i)\n",
    "    \n",
    "    for i in G.nodes():\n",
    "        G.add_edge(i, (i + 1) % n)\n",
    "\n",
    "    for i in G.nodes():\n",
    "        for j in G.nodes():\n",
    "            if 0 < abs(i - j) % (n - 1 - k / 2) <= k / 2:\n",
    "                G.add_edge(i, j)\n",
    "\n",
    "    Gs = []\n",
    "    results = []\n",
    "\n",
    "    for i in G.nodes():\n",
    "        neighbors = list(G.neighbors(i))\n",
    "        for j in neighbors:\n",
    "            if 0 < (j - i) % n <= k / 2:\n",
    "                if np.random.uniform() <= beta:\n",
    "                        while True:\n",
    "                            if method == 'W-S':\n",
    "                                v = random.choice(list(set(G.nodes())))\n",
    "                            elif method == 'llm':\n",
    "                                result = select_neighbor(G, i, temperature)\n",
    "                                if not result:\n",
    "                                    break\n",
    "                                v = result['name']\n",
    "                                \n",
    "                            if v != i and v not in G.neighbors(i):\n",
    "                                if method == 'llm':\n",
    "                                    results.append(result)\n",
    "                                G.add_edge(i, v)\n",
    "                                G.remove_edge(i, j)\n",
    "                                break     \n",
    "                       \n",
    "                        \n",
    "        Gs.append(G.copy())\n",
    "\n",
    "    return Gs, results\n",
    "\n",
    "def select_neighbor(G, t, temperature):\n",
    "    features = []\n",
    "    for v in G.nodes():\n",
    "        if v != t and v not in G.neighbors(t):\n",
    "            features.append({'name' : v, 'neighbors' : list(G.neighbors(v))})\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    # Task\n",
    "    Your task is to select a person to be friends with.\n",
    "\n",
    "    # Input\n",
    "    The input is a list of dictionaries. Each dictionary has two keys: 'name', 'neighbors'.\n",
    "    'name' is the name of the person, and 'neighbors' is a list of the person's friends.\n",
    "    The data is given below after chevrons:\n",
    "    <DEGREES>\n",
    "    {json.dumps(features, indent=4)}\n",
    "    </DEGREES>\n",
    "\n",
    "    # Output\n",
    "    The output should be given in JSON format with the following structure\n",
    "\n",
    "    {{\n",
    "        \"name\" : name of the person you selected,\n",
    "        \"reason\" : reason for selecting the person\n",
    "    }}\n",
    "\n",
    "    # Notes\n",
    "    - The output must be a valid JSON object.\n",
    "\n",
    "    ```json\n",
    "    \"\"\"   \n",
    "\n",
    "    for i in range(10):\n",
    "        try:\n",
    "            result = json.loads(get_response(prompt, temperature=temperature).split('```')[0])\n",
    "            if result['name'] in G.nodes():    \n",
    "                print('NEW EDGE', result)\n",
    "                return result \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "      \n",
    "\n",
    "def run_network_formation_experiment(n_min, n_max, n_step, k, beta, num_simulations, outfile, temperatures, method):\n",
    "    saved_scenarios = set()\n",
    "\n",
    "    if os.path.exists(outfile):\n",
    "        with open(outfile) as f:\n",
    "            lines = f.read().splitlines()\n",
    "\n",
    "            for line in lines:\n",
    "                scenario = json.loads(line)\n",
    "                saved_scenarios.add((scenario['n'], scenario['simulation'], scenario['k'], scenario['beta'], scenario['temperature']))\n",
    "\n",
    "        exit()\n",
    "\n",
    "    f = open(outfile, 'a+')\n",
    "\n",
    "\n",
    "    for n in range(n_min, n_max + 1, n_step):\n",
    "        for i in range(num_simulations):\n",
    "            for temperature in temperatures:\n",
    "                if (n, i, k, beta, temperature) in saved_scenarios:\n",
    "                    print(f'Skipping simulation for n={n}, i={i}, k={k}, beta={beta}, temperature={temperature}')\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f'Running simulation for n={n}, i={i}, k={k}, beta={beta}, temperature={temperature}')\n",
    "\n",
    "                    Gs, reasons = network_growth(n, k, beta, temperature=temperature, method=method)\n",
    "\n",
    "                    temp = {\n",
    "                        'n' : n,\n",
    "                        'k' : k,\n",
    "                        'beta' : beta,\n",
    "                        'temperature' : temperature,\n",
    "                        'simulation' : i,\n",
    "                        'graphs' : [nx.to_dict_of_lists(G) for G in Gs],\n",
    "                        'reasons' : reasons\n",
    "                    }    \n",
    "\n",
    "                    f.write(json.dumps(temp) + '\\n')            \n",
    "\n",
    "                if method != 'llm':\n",
    "                    break\n",
    "\n",
    "    f.close()\n",
    "\n",
    "def draw_graph(G, ax, G0=None, use_netgraph=True):\n",
    "    if not use_netgraph:\n",
    "        pos = nx.circular_layout(G)\n",
    "        nx.draw(G, pos, ax=ax, node_size=10, width=1.5, node_color='#d35400', alpha=0.7, edge_color='#2c3e50')\n",
    "    else:\n",
    "        netgraph.Graph(G, ax=ax, node_size=2.5, edge_width=1, node_color='#d35400', edge_color='#2c3e50', node_layout='circular', edge_layout='bundled', edge_layout_kwargs=dict(k=2000))\n",
    "    ax.set_axis_off()\n",
    "            \n",
    "def analyze_experiments(filename, suffix='', fit_beta_method='binary_search'):\n",
    "\n",
    "    with open(filename) as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for line in lines:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "\n",
    "    average_shortest_path_lengths = collections.defaultdict(list)\n",
    "    average_clustering_coefficients = collections.defaultdict(list)\n",
    "    graphs = {}\n",
    "    hat_betas = []\n",
    "    temperatures = set()\n",
    "\n",
    "    for d in data:\n",
    "        Gs = []\n",
    "        for graph in d['graphs']:\n",
    "            G = nx.Graph()\n",
    "\n",
    "            for k, v in graph.items():\n",
    "                k = int(k)\n",
    "                G.add_node(k)\n",
    "                for n in v:\n",
    "                    G.add_edge(k, n)\n",
    "\n",
    "            Gs.append(G)\n",
    "\n",
    "        hat_beta = fit_beta_ws(Gs[-1], d['k'], method=fit_beta_method)\n",
    "\n",
    "        average_shortest_path_len = [nx.average_shortest_path_length(G) for G in Gs]\n",
    "        average_clustering_coefficient = [nx.average_clustering(G) for G in Gs]\n",
    "        average_shortest_path_lengths[d['n'], d['k'], d['beta'], d['temperature']].append(average_shortest_path_len)\n",
    "        average_clustering_coefficients[d['n'], d['k'], d['beta'], d['temperature']].append(average_clustering_coefficient)\n",
    "\n",
    "        Gs_WS_estimated, _ = network_growth(d['n'], d['k'], hat_beta, d['temperature'], method='W-S')\n",
    "\n",
    "        G_WS_estimated = Gs_WS_estimated[-1]\n",
    "\n",
    "        average_shortest_path_len_WS_estimated = nx.average_shortest_path_length(G_WS_estimated)\n",
    "        average_clustering_coefficient_WS_estimated = nx.average_clustering(G_WS_estimated)\n",
    "\n",
    "        hat_beta_record = {\n",
    "            'n' : d['n'],\n",
    "            'k' : d['k'],\n",
    "            'beta' : d['beta'],\n",
    "            'hat_beta' : hat_beta,\n",
    "            'Temperature' : d['temperature'],\n",
    "            'Simulation' : d['simulation'],\n",
    "            'Diff. in Avg. Shortest Path Length' : average_shortest_path_len_WS_estimated - average_shortest_path_len[-1],\n",
    "            'Diff. in Avg. Clustering Coefficient' : average_clustering_coefficient_WS_estimated - average_clustering_coefficient[-1],\n",
    "            'Avg. Shortest Path Length' : average_shortest_path_len[-1],\n",
    "            'Avg. Clustering Coefficient' : average_clustering_coefficient[-1],\n",
    "            'Avg. Shortest Path Length WS' : average_shortest_path_len_WS_estimated,\n",
    "            'Avg. Clustering Coefficient WS' : average_clustering_coefficient_WS_estimated\n",
    "        }\n",
    "\n",
    "        hat_betas.append(hat_beta_record)\n",
    "        \n",
    "        temperatures.add(d['temperature'])\n",
    "\n",
    "        graphs[d['n'], d['k'], d['beta'], d['temperature'], d['simulation']] = Gs[-1].copy()\n",
    "\n",
    "    fig_final, ax_final = plt.subplots(1, 2 + len(average_shortest_path_lengths), figsize=(5 * (2 + len(average_shortest_path_lengths)), 5), squeeze=False, gridspec_kw={'width_ratios' : [1] * len(average_shortest_path_lengths) + [0.5, 0.5]})\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for key in sorted(graphs.keys()):\n",
    "        if key[-1] == 0:\n",
    "            G = graphs[key]\n",
    "            draw_graph(G, ax_final[0, i])\n",
    "            ax_final[0, i].set_title(f'Temperature = {key[3]}')\n",
    "\n",
    "            i += 1\n",
    "\n",
    "    ax_final[0, -1].set_ylabel('Average Shortest Path Length')\n",
    "    ax_final[0, -2].set_ylabel('Average Clustering Coefficient')\n",
    "\n",
    "\n",
    "    palette = ['#2980b9', '#f1c40f', '#7f8c8d', '#d35400', '#34495e', '#e67e22',]\n",
    "\n",
    "    fig, ax = plt.subplots(2, len(average_shortest_path_lengths), figsize=(5 * len(average_shortest_path_lengths), 10), squeeze=False)\n",
    "    fig_combined, ax_combined = plt.subplots(1, 2, figsize=(10, 5), squeeze=False)\n",
    "\n",
    "    ax_combined[0, 0].set_ylabel('Average Shortest Path Length')\n",
    "    ax_combined[0, 1].set_ylabel('Average Clustering Coefficient')\n",
    "    ax_combined[0, 0].set_xlabel('t')\n",
    "    ax_combined[0, 1].set_xlabel('t')\n",
    "\n",
    "\n",
    "    for i, (k, c) in enumerate(zip(sorted(average_shortest_path_lengths.keys()), palette)):\n",
    "        v = average_shortest_path_lengths[k]\n",
    "        v = np.array(v)\n",
    "\n",
    "        mean = v.mean(axis=0)\n",
    "        std = v.std(axis=0)\n",
    "\n",
    "        ci = 1.96 * std / np.sqrt(len(v))\n",
    "        \n",
    "        ax[0, i].plot(mean, color='#34495e', label='LLM')\n",
    "        ax[0, i].fill_between(np.arange(len(mean)), mean - ci, mean + ci, alpha=0.2, color='#34495e')\n",
    "\n",
    "        ax[0, i].set_title(f'Temperature = {k[3]}')\n",
    "\n",
    "        ax[0, i].set_xlabel('t')\n",
    "        ax[0, i].set_ylabel('Average Shortest Path Length')\n",
    "\n",
    "        ax[0, i].set_xlim(0, len(mean) - 1)\n",
    "\n",
    "        ax_combined[0, 0].plot(mean, color=c, label='Temp = ' + str(k[3]))\n",
    "        ax_combined[0, 0].fill_between(np.arange(len(mean)), mean - ci, mean + ci, alpha=0.2, color=c)\n",
    "\n",
    "        ax_final[0, -1].bar(i, mean[-1], yerr=2*ci[-1], color=c, alpha=0.5, label='Temp = ' + str(k[3]))\n",
    "\n",
    "        for k_prime in sorted(average_shortest_path_lengths.keys()):\n",
    "            if k[-1] > k_prime[-1]:\n",
    "                print(f'T-test for Temperatures {k[-1]} and {k_prime[-1]} for Average shortest path length: {scipy.stats.ttest_ind([x[-1] for x in average_shortest_path_lengths[k]], [x[-1] for x in average_shortest_path_lengths[k_prime]], equal_var=False, alternative=\"less\")}')\n",
    "\n",
    "\n",
    "    for i, (k, c) in enumerate(zip(sorted(average_clustering_coefficients.keys()), palette)):\n",
    "        v = average_clustering_coefficients[k]\n",
    "        v = np.array(v)\n",
    "\n",
    "        mean = v.mean(axis=0)\n",
    "        std = v.std(axis=0)\n",
    "\n",
    "        ci = 1.96 * std / np.sqrt(len(v))\n",
    "        \n",
    "        ax[1, i].plot(mean, color='#34495e', label='LLM')\n",
    "        ax[1, i].fill_between(np.arange(len(mean)), mean - ci, mean + ci, alpha=0.2, color='#34495e')\n",
    "\n",
    "        ax[1, i].set_ylabel('Average Clustering Coefficient')\n",
    "\n",
    "        ax[1, i].set_xlabel('t')\n",
    "\n",
    "        ax[1, i].set_xlim(0, len(mean) - 1)\n",
    "\n",
    "        ax_combined[0, 1].plot(mean, color=c, label='Temp = ' + str(k[3]))\n",
    "        ax_combined[0, 1].fill_between(np.arange(len(mean)), mean - ci, mean + ci, alpha=0.2, color=c)\n",
    "\n",
    "        ax_final[0, -2].bar(i, mean[-1], yerr=2*ci[-1], color=c, alpha=0.5, label='Temp = ' + str(k[3]))\n",
    "\n",
    "        for k_prime in sorted(average_clustering_coefficients.keys()):\n",
    "            if k[-1] > k_prime[-1]:\n",
    "                print(f'T-test for Temperatures {k[-1]} and {k_prime[-1]} for Average clustering coefficient: {scipy.stats.ttest_ind([x[-1] for x in average_clustering_coefficients[k]], [x[-1] for x in average_clustering_coefficients[k_prime]], equal_var=False, alternative=\"less\")}')\n",
    "\n",
    "    # Null models\n",
    "    average_shortest_path_lengths_null = { 'W-S' : collections.defaultdict(list), 'random' : collections.defaultdict(list) }\n",
    "    average_clustering_coefficients_null = { 'W-S' : collections.defaultdict(list), 'random' : collections.defaultdict(list) }\n",
    "\n",
    "    for d in data:\n",
    "        for method in ['W-S']:\n",
    "            if method == 'random':\n",
    "                Gs, _ = network_growth(d['n'], d['k'], 1, d['temperature'], method='W-S')\n",
    "            else:\n",
    "                Gs, _ = network_growth(d['n'], d['k'], d['beta'], d['temperature'], method=method)\n",
    "            average_shortest_path_lengths_null[method][d['n'], d['k'], d['beta'], d['temperature']].append([nx.average_shortest_path_length(G) for G in Gs])\n",
    "            average_clustering_coefficients_null[method][d['n'], d['k'], d['beta'], d['temperature']].append([nx.average_clustering(G) for G in Gs])\n",
    "\n",
    "    for method in ['W-S']:\n",
    "        for i, (k, v) in enumerate(average_shortest_path_lengths_null[method].items()):\n",
    "            v = np.array(v)\n",
    "\n",
    "            mean = v.mean(axis=0)\n",
    "            std = v.std(axis=0)\n",
    "\n",
    "            ci = 1.96 * std / np.sqrt(len(v))\n",
    "\n",
    "            if method == 'W-S':\n",
    "                ax[0, i].plot(mean, color='#d35400', linestyle='--', label=method)\n",
    "            elif method == 'random':\n",
    "                ax[0, i].plot(mean, color='#d35400', linestyle=':', label=method)\n",
    "            \n",
    "            ax[0, i].fill_between(np.arange(len(mean)), mean - ci, mean + ci, alpha=0.2, color='#d35400', hatch='||')\n",
    "\n",
    "            if i == 0:\n",
    "                ax_combined[0, 0].plot(mean, color='#d35400', linestyle='--', label=method)\n",
    "                ax_combined[0, 0].fill_between(np.arange(len(mean)), mean - ci, mean + ci, alpha=0.2, color='#d35400', hatch='||')\n",
    "\n",
    "                ax_final[0, -1].bar(len(average_shortest_path_lengths), mean[-1], yerr=2*ci[-1], color='#d35400', alpha=0.5, label=method)\n",
    "\n",
    "            for k_prime in sorted(average_shortest_path_lengths.keys()):\n",
    "                if k == k_prime:\n",
    "                    print(f'T-test for Temperature {k[-1]} and W-S for Average shortest path length (two-sided): {scipy.stats.ttest_ind([x[-1] for x in average_shortest_path_lengths_null[method]], [x[-1] for x in average_shortest_path_lengths[k_prime]], equal_var=False, alternative=\"two-sided\")}')            \n",
    "\n",
    "\n",
    "    for method in ['W-S']:\n",
    "        for i, (k, v) in enumerate(average_clustering_coefficients_null[method].items()):\n",
    "            v = np.array(v)\n",
    "\n",
    "            mean = v.mean(axis=0)\n",
    "            std = v.std(axis=0)\n",
    "\n",
    "            ci = 1.96 * std / np.sqrt(len(v))\n",
    "\n",
    "            if method == 'W-S':\n",
    "                ax[1, i].plot(mean, color='#d35400', linestyle='--', label=method)\n",
    "            elif method == 'random':\n",
    "                ax[1, i].plot(mean, color='#d35400', linestyle=':', label=method)\n",
    "            \n",
    "            ax[1, i].fill_between(np.arange(len(mean)), mean - ci, mean + ci, alpha=0.2, color='#d35400', hatch='||')\n",
    "\n",
    "            if i == 0:\n",
    "                ax_combined[0, 1].plot(mean, color='#d35400', linestyle='--', label=method)\n",
    "                ax_combined[0, 1].fill_between(np.arange(len(mean)), mean - ci, mean + ci, alpha=0.2, color='#d35400', hatch='||')\n",
    "\n",
    "                ax_final[0, -2].bar(len(average_shortest_path_lengths), mean[-1], yerr=2*ci[-1], color='#d35400', alpha=0.5, label=method)\n",
    "\n",
    "            for k_prime in sorted(average_clustering_coefficients.keys()):\n",
    "                if k == k_prime:\n",
    "                    print(f'T-test for Temperature {k[-1]} and W-S for Average clustering coefficient (greater): {scipy.stats.ttest_ind([x[-1] for x in average_clustering_coefficients_null[method]], [x[-1] for x in average_clustering_coefficients[k_prime]], equal_var=False, alternative=\"greater\")}')                   \n",
    "    ax_final[0, -1].set_xticks([])\n",
    "    ax_final[0, -2].set_xticks([])\n",
    "\n",
    "    ax_final[0, -1].legend(bbox_to_anchor=(1, 0.5), loc='center left', frameon=False)\n",
    "\n",
    "\n",
    "    for i in range(len(average_shortest_path_lengths)):\n",
    "        ax[0, i].legend(loc='upper left')\n",
    "        ax[1, i].legend(loc='upper left')\n",
    "\n",
    "        ax[0, i].set_ylim(2, 3)\n",
    "\n",
    "    ax_combined[0, 0].legend(loc='upper right')\n",
    "\n",
    "    fig_combined.tight_layout()\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig.savefig(f'figures/principle_5/principle_5_overall{f\"_{suffix}\" if suffix else \"\"}.png')\n",
    "   \n",
    "    fig_combined.savefig(f'figures/principle_5/principle_5_overall_combined{f\"_{suffix}\" if suffix else \"\"}.png')\n",
    "    \n",
    "    fig_final.tight_layout()\n",
    "\n",
    "    fig_final.savefig(f'figures/principle_5/principle_5_final_graphs{f\"_{suffix}\" if suffix else \"\"}.png')\n",
    "\n",
    "    hat_betas = pd.DataFrame.from_records(hat_betas)\n",
    "\n",
    "    fig_estimated, ax_estimated = plt.subplots(1, 2, figsize=(10, 5), squeeze=False)\n",
    "\n",
    "    sns.boxplot(data=hat_betas, x='Temperature', y='hat_beta', ax=ax_estimated[0, 0], palette='Set2')\n",
    "    ax_estimated[0, 0].set_ylabel('Estimated $\\hat{\\\\beta}$')\n",
    "    \n",
    "    sns.violinplot(data=hat_betas, x='Temperature', y='Diff. in Avg. Shortest Path Length', ax=ax_estimated[0, 1], palette='Set2')\n",
    "\n",
    "    fig_estimated.tight_layout()\n",
    "\n",
    "    fig_estimated.savefig(f'figures/principle_5/principle_5_estimated_beta{f\"_{suffix}\" if suffix else \"\"}.png')\n",
    "\n",
    "    for temperature in temperatures:\n",
    "        df_temp = hat_betas.query(f'Temperature == {temperature}')\n",
    "        print('T-test for average path length vs WS with estimated beta for temperature', temperature, ':', scipy.stats.ttest_ind(df_temp['Avg. Shortest Path Length'], df_temp['Avg. Shortest Path Length WS'], equal_var=False, alternative=\"two-sided\"))\n",
    "            \n",
    "def plot_multiple_networks_small_world(filename, outfile, fit_beta_method='binary_search'):\n",
    "\n",
    "    with open(filename) as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for line in lines:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "    records = []\n",
    "\n",
    "    temperatures = set()\n",
    "    seen = set()\n",
    "\n",
    "    for d in data:\n",
    "        Gs = []\n",
    "        for graph in d['graphs']:\n",
    "            G = nx.Graph()\n",
    "\n",
    "            for k, v in graph.items():\n",
    "                k = int(k)\n",
    "                G.add_node(k)\n",
    "                for n in v:\n",
    "                    G.add_edge(k, n)\n",
    "\n",
    "            Gs.append(G)\n",
    "\n",
    "        try:\n",
    "            average_shortest_path_len = nx.average_shortest_path_length(Gs[-1])\n",
    "            average_clustering_coefficient = nx.average_clustering(Gs[-1])\n",
    "            hat_beta = fit_beta_ws(Gs[-1], d['k'], method=fit_beta_method)\n",
    "        \n",
    "            record = {\n",
    "                'n' : d['n'],\n",
    "                'log(n)' : np.log(d['n']), \n",
    "                '1/log(n)' : 1 / np.log(d['n']),\n",
    "                'k' : d['k'],\n",
    "                'beta' : d['beta'],\n",
    "                'hat_beta' : hat_beta,\n",
    "                'temperature' : d['temperature'],\n",
    "                'simulation' : d['simulation'],\n",
    "                'Average Shortest Path Length' : average_shortest_path_len,\n",
    "                'Average Clustering Coefficient' : average_clustering_coefficient\n",
    "            }\n",
    "\n",
    "\n",
    "            temperatures.add(d['temperature'])\n",
    "            records.append(record)\n",
    "\n",
    "\n",
    "            seen.add((d['n'], d['k'], d['beta']))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    for n, k, beta in seen:\n",
    "        try:\n",
    "            Gs, _ = network_growth(n, k, beta, 0, method='W-S')\n",
    "\n",
    "            average_shortest_path_len = nx.average_shortest_path_length(Gs[-1])\n",
    "            average_clustering_coefficient = nx.average_clustering(Gs[-1])\n",
    "\n",
    "            record = {\n",
    "                'n' : n,\n",
    "                'log(n)' : np.log(n),\n",
    "                '1/log(n)' : 1 / np.log(n),\n",
    "                'k' : k,\n",
    "                'beta' : beta,\n",
    "                'temperature' : 'W-S',\n",
    "                'simulation' : 0,\n",
    "                'Average Shortest Path Length' : average_shortest_path_len,\n",
    "                'Average Clustering Coefficient' : average_clustering_coefficient\n",
    "            }\n",
    "\n",
    "            records.append(record)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5), squeeze=False)\n",
    "\n",
    "    for temperature in temperatures:\n",
    "        regress_result = scipy.stats.linregress(df.query(f'temperature == {temperature}')['log(n)'], df.query(f'temperature == {temperature}')['Average Shortest Path Length'])\n",
    "        stars = '***' if regress_result.pvalue < 0.001 else '**' if regress_result.pvalue < 0.01 else '*' if regress_result.pvalue < 0.05 else ''\n",
    "\n",
    "        sns.regplot(data=df.query(f'temperature == {temperature}'), x='log(n)', y='Average Shortest Path Length', ax=ax[0, 0], label=f'{temperature}, $a$ = {regress_result.slope:.2f} ({stars})')   \n",
    "\n",
    "\n",
    "    regress_result = scipy.stats.linregress(df.query(f'temperature == \"W-S\"')['log(n)'], df.query(f'temperature == \"W-S\"')['Average Shortest Path Length'])\n",
    "    stars = '***' if regress_result.pvalue < 0.001 else '**' if regress_result.pvalue < 0.01 else '*' if regress_result.pvalue < 0.05 else ''\n",
    "    sns.regplot(data=df.query(f'temperature == \"W-S\"'), x='log(n)', y='Average Shortest Path Length', ax=ax[0, 0], label=f'W-S, $a$ = {regress_result.slope:.2f} ({stars})')   \n",
    "    \n",
    "\n",
    "    ax[0, 0].legend(fontsize=0.75*SMALL_SIZE, loc='lower right')\n",
    "\n",
    "    for temperature in temperatures:\n",
    "        regress_result = scipy.stats.linregress(df.query(f'temperature == {temperature}')['1/log(n)'], df.query(f'temperature == {temperature}')['Average Clustering Coefficient'])\n",
    "        stars = '(***)' if regress_result.pvalue < 0.001 else '(**)' if regress_result.pvalue < 0.01 else '(*)' if regress_result.pvalue < 0.05 else ''\n",
    "        sns.regplot(data=df.query(f'temperature == {temperature}'), x='1/log(n)', y='Average Clustering Coefficient', ax=ax[0, 1], label=f'{temperature}, $a$ = {regress_result.slope:.2f} {stars}')\n",
    "\n",
    "    regress_result = scipy.stats.linregress(df.query(f'temperature == \"W-S\"')['1/log(n)'], df.query(f'temperature == \"W-S\"')['Average Clustering Coefficient'])\n",
    "    stars = '(***)' if regress_result.pvalue < 0.001 else '(**)' if regress_result.pvalue < 0.01 else '(*)' if regress_result.pvalue < 0.05 else ''\n",
    "    sns.regplot(data=df.query(f'temperature == \"W-S\"'), x='1/log(n)', y='Average Clustering Coefficient', ax=ax[0, 1], label=f'W-S, $a$ = {regress_result.slope:.2f} {stars}')\n",
    "\n",
    "    ax[0, 1].legend(fontsize=0.75*SMALL_SIZE, loc='lower right')\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig.savefig(outfile, dpi=300, bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM-based\n",
    "\n",
    "for i, beta in enumerate([0.25, 0.5, 0.75], 1):\n",
    "\n",
    "    run_network_formation_experiment(20, 20, 1, 5, beta, 10, f'outputs/principle_5_{i}.jsonl', [0.5, 1.0, 1.5], method='llm')\n",
    "    analyze_experiments(f'outputs/principle_5_{i}.jsonl', fit_beta_method='binary_search' if beta != 0.75 else 'closed_form')\n",
    "\n",
    "    # run_network_formation_experiment(10, 100, 10, 5, beta, 1, f'outputs/principle_5_multiple_{i}.jsonl', [0.5, 1.0, 1.5], method='llm')\n",
    "    # plot_multiple_networks_small_world(f'outputs/principle_5_multiple_{i}.jsonl', f'figures/principle_5/principle_5_small_world_{i}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories = [{'category': 'Large circle', 'description': 'People who have a large number of friends and are connected to many other people in the network.'}, \n",
    "#               {'category': 'Mutual friends', 'description': 'People who have many common friends with the person making the selection.'}]\n",
    "\n",
    "# summarize_reasons('outputs/principle_5.jsonl', categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
