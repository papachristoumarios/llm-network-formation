{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import scipy.stats as stats\n",
    "\n",
    "import seaborn as sns\n",
    "import json\n",
    "import openai\n",
    "import random\n",
    "import os\n",
    "import collections\n",
    "import itertools\n",
    "import copy\n",
    "import dataloader\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "import netgraph\n",
    "import scipy\n",
    "import ast\n",
    "from utils import get_response, summarize_reasons\n",
    "\n",
    "MEDIUM_SIZE = 28\n",
    "SMALL_SIZE = 0.85 * MEDIUM_SIZE\n",
    "BIGGER_SIZE = 1.5 * MEDIUM_SIZE\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "# gpt-4-1106-preview\n",
    "\n",
    "# def summarize_reasons(filenames, name, n_samples=50, n_categories=4, n_resamples=5, categories=None, model='gpt-4-1106-preview'):\n",
    "#     random.seed(1)\n",
    "#     np.random.seed(1)\n",
    "\n",
    "#     reason_list = collections.defaultdict(list)\n",
    "\n",
    "#     all_reasons = []\n",
    "\n",
    "#     for filename in filenames:\n",
    "#         data = []\n",
    "\n",
    "#         with open(filename) as f:\n",
    "#             lines = f.read().splitlines()\n",
    "\n",
    "\n",
    "#         for line in lines:\n",
    "\n",
    "#             data.append(json.loads(line))\n",
    "\n",
    "\n",
    "#         for d in data:        \n",
    "#             for results in d[\"results\"]:\n",
    "#                 for result in results:\n",
    "#                     if result and 'reason' in result.keys():\n",
    "#                         reason_list[d['temperature']].append(result['reason'])\n",
    "#                         all_reasons.append(result['reason'])\n",
    "\n",
    "#     if categories is None:\n",
    "#         categorization_prompt = f\"\"\"\n",
    "#         # Task\n",
    "\n",
    "#         You are given a list of reasons and your task to find {n_categories} categories that best describe the reasons.\n",
    "\n",
    "#         # Input\n",
    "\n",
    "#         The input is a list of reasons. The list is given below after chevrons:\n",
    "#         <REASONS>\n",
    "#         {json.dumps(random.sample(all_reasons, len(reason_list) * n_samples))}\n",
    "#         </REASONS>\n",
    "\n",
    "#         # Output\n",
    "\n",
    "#         The output should be given in JSON format with the following structure:\n",
    "\n",
    "#         [\n",
    "#             {{\n",
    "#                 \"category\" : category,\n",
    "#                 \"description\" : short description of the category\n",
    "#             }}, ...\n",
    "#         ]\n",
    "\n",
    "#         # Notes\n",
    "#         * The names of the categories must be descriptive and mutually exclusive.\n",
    "\n",
    "#         ```json\n",
    "#         \"\"\"\n",
    "\n",
    "#         for _ in range(10):\n",
    "#             try:\n",
    "#                 ans = get_response(categorization_prompt, temperature=0, system_prompt=\"You are a helpful assistant\", model=model)\n",
    "#                 categories = json.loads(ans.lstrip('```json').rstrip('```'))\n",
    "#                 print(categories)\n",
    "#                 break\n",
    "\n",
    "#             except Exception as e:\n",
    "#                 print(e)\n",
    "        \n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "#     category_list = [c['category'] for c in categories]\n",
    "\n",
    "#     records = []\n",
    "\n",
    "#     for i, (k, v) in enumerate(reason_list.items()):\n",
    "#         print('Temperature', k)\n",
    "#         if len(v) <= n_samples:\n",
    "#             n_resamples = 1\n",
    "\n",
    "#         for r in range(n_resamples):\n",
    "#             prompt = f\"\"\"\n",
    "#             # Task\n",
    "#             You are given a list of reasons and your task is to classify them into categories.\n",
    "\n",
    "#             # Input\n",
    "#             The input is a list of reasons. The list is given below after chevrons:\n",
    "#             <REASONS>\n",
    "#             {json.dumps(random.sample(v, n_samples), indent=4)}\n",
    "#             </REASONS>\n",
    "\n",
    "#             ## Categories\n",
    "#             The names of the categories are given below after chevrons:\n",
    "#             <CATEGORIES>\n",
    "#             {json.dumps(categories, indent=4)}\n",
    "#             </CATEGORIES>\n",
    "\n",
    "#             Each reason must be assigned to exactly one of the categories.\n",
    "            \n",
    "#             # Output\n",
    "#             The output should be given as a list of JSON objects with the following structure:\n",
    "\n",
    "#             [\n",
    "#                 {{\n",
    "#                         \"reason\" : reason,\n",
    "#                         \"category\" : category name\n",
    "#                 }}, ...\n",
    "#             ]\n",
    "\n",
    "#             ```json\n",
    "#             \"\"\"\n",
    "\n",
    "#             for _ in range(10):\n",
    "#                 try:\n",
    "#                     ans = get_response(prompt, temperature=0, system_prompt=\"You are a helpful assistant\", model=model)\n",
    "\n",
    "#                     result =  json.loads(ans.lstrip('```json').rstrip('```'))\n",
    "\n",
    "\n",
    "#                     assert(isinstance(result, list))\n",
    "\n",
    "#                     reason_types = collections.defaultdict(float)\n",
    "\n",
    "#                     total = 0\n",
    "\n",
    "#                     for reason in result:\n",
    "#                         if reason['category'] in category_list:\n",
    "#                             reason_types[reason['category']] += 1\n",
    "#                             total += 1\n",
    "\n",
    "#                     for key, val in reason_types.items():\n",
    "#                         reason_types[key] = val / total * 100\n",
    "\n",
    "                   \n",
    "#                     break\n",
    "#                 except Exception as e:\n",
    "#                     print(e)\n",
    "\n",
    "#             for key, val in reason_types.items():\n",
    "#                 records.append({\n",
    "#                     'Temperature' : k,\n",
    "#                     'Category' : key,\n",
    "#                     'Frequency' : val,\n",
    "#                     'Resample' : r\n",
    "#                 })\n",
    "            \n",
    "#     df = pd.DataFrame.from_records(records)\n",
    "\n",
    "#     fig.suptitle(f'Reasoning for {name}', fontsize=MEDIUM_SIZE)\n",
    "\n",
    "#     sns.barplot(data=df, x='Category', y='Frequency', hue='Temperature', ax=ax, palette='Set2', hue_order=sorted(reason_list.keys()), order=sorted(category_list))\n",
    "\n",
    "#     plt.legend(fontsize=0.6*SMALL_SIZE, title='Temperature', loc='upper left')\n",
    "\n",
    "#     plt.xticks(rotation=0, fontsize=0.6*SMALL_SIZE)\n",
    "\n",
    "#     # T-test\n",
    "\n",
    "#     for k in sorted(reason_list.keys()):\n",
    "#         for category1, category2 in itertools.combinations(category_list, 2):\n",
    "#             print(f'Temperature: {k}, Category 1: {category1}, Category 2: {category2}')\n",
    "#             print(stats.ttest_ind(df.query(f'Temperature == {k} and Category == \"{category1}\"')['Frequency'], df.query(f'Temperature == {k} and Category == \"{category2}\"')['Frequency'], equal_var=False, alternative='greater'))\n",
    "\n",
    "\n",
    "#     fig.tight_layout()\n",
    "\n",
    "#     fig.savefig(f'figures/combined_model/{name}_reasons.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "def network_growth(G0, temperature, num_choices=1, method='llm', num_samples=-1, num_nodes_samples=-1, model='gpt-4-1106-preview'):\n",
    "    # Set seed\n",
    "    random.seed(0)\n",
    "    np.random.seed(0)    \n",
    "\n",
    "    # Copy the ground truth graph\n",
    "    G = G0.copy()\n",
    "   \n",
    "    Gs = [G.copy()]\n",
    "\n",
    "    profiles = nx.get_node_attributes(G, 'features')\n",
    "\n",
    "    # Edges to drop\n",
    "    dropped_edges = []\n",
    "\n",
    "    if num_nodes_samples > 0:\n",
    "        nodes = random.sample(G.nodes(), min(len(G), num_nodes_samples))\n",
    "    else:\n",
    "        nodes = G.nodes()\n",
    "\n",
    "    # Drop one neighbor for each node\n",
    "    for v in nodes:\n",
    "        dropped_v_edges = []\n",
    "        for _ in range(num_choices):\n",
    "            if len(list(G.neighbors(v))) > 0:\n",
    "                \n",
    "                while True:\n",
    "                    u = random.choice(list(G.neighbors(v)))\n",
    "                    if (v, u) not in dropped_edges:\n",
    "                        dropped_v_edges.append((v, u))\n",
    "                        G.remove_edge(v, u)\n",
    "                        break\n",
    "\n",
    "        dropped_edges.append(dropped_v_edges)\n",
    "\n",
    "    Gs = [G.copy()]\n",
    "    results = []\n",
    "    candidates = []\n",
    "\n",
    "\n",
    "    for i, t in enumerate(nodes):\n",
    "\n",
    "        if method == 'llm':\n",
    "            result, candidate = select_neighbor(G, t, profiles, temperature, num_choices=len(dropped_edges[i]), dropped_nodes=[u for (_, u) in dropped_edges[i]], num_samples=num_samples, model=model)\n",
    "\n",
    "            if result:\n",
    "                for r in result:\n",
    "                    v = r['name']\n",
    "                    r['edge'] = (t, v)\n",
    "                    G.add_edge(t, v, similarity=r['similarity'])\n",
    "                results.append(result)\n",
    "\n",
    "            candidates.append(candidate)\n",
    "        elif method in ['random', 'homophilous', 'heterophilous', 'ground_truth']:\n",
    "            if num_samples > 0:\n",
    "                choice_set = random.sample([v for v in G.nodes() if v != t], num_samples)\n",
    "            else:\n",
    "                choice_set = [v for v in G.nodes() if v != t]\n",
    "\n",
    "            if method == 'random':\n",
    "                new_nodes = random.sample(choice_set, len(dropped_edges[i]))\n",
    "            elif method == 'homophilous':\n",
    "                new_nodes = list(sorted(choice_set, key=lambda v: measure_similarity(profiles[t], profiles[v])['common_attributes'], reverse=True))[:len(dropped_edges[i])]\n",
    "            elif method == 'heterophilous':\n",
    "                new_nodes = list(sorted(choice_set, key=lambda v: measure_similarity(profiles[t], profiles[v])['common_attributes']))[:len(dropped_edges[i])]\n",
    "            elif method == 'ground_truth':\n",
    "                new_nodes = [e[1] for e in dropped_edges[i]]\n",
    "\n",
    "            result = []\n",
    "\n",
    "            for v in new_nodes:\n",
    "                print(f'Node: {t}, Link: {v}')\n",
    "                similarity = measure_similarity(profiles[t], profiles[v])\n",
    "                G.add_edge(t, v, similarity=similarity, weight=similarity['common_attributes'])\n",
    "            \n",
    "                result.append({'name' : v, 'similarity' : similarity, 'reason' : method})\n",
    "\n",
    "            candidate = []\n",
    "\n",
    "            for v in choice_set:\n",
    "                similarity = measure_similarity(profiles[t], profiles[v])\n",
    "                candidate.append({'name' : v, 'similarity' : similarity, 'reason' : method})\n",
    "\n",
    "            candidates.append(candidate)\n",
    "            results.append(result)\n",
    "\n",
    "        Gs.append(G.copy())\n",
    "\n",
    "    return Gs, results, candidates\n",
    "\n",
    "def fit_dcm(results):\n",
    "\n",
    "    similarities = [r['similarity'] for result in results for r in result]\n",
    "    similarities_df = pd.DataFrame.from_records(similarities)\n",
    "    similarities_df = sm.add_constant(similarities_df)\n",
    "\n",
    "    outcomes = np.array([r['edge'][1] for result in results for r in result])\n",
    "\n",
    "    print(similarities_df)\n",
    "\n",
    "    mnl_model = sm.MNLogit(outcomes, similarities_df)\n",
    "    mnl_results = mnl_model.fit()\n",
    "\n",
    "    print(mnl_results.summary())\n",
    "\n",
    "    return mnl_results\n",
    "\n",
    "def measure_similarity(profile1, profile2):\n",
    "    similarity = {\n",
    "        'common_attributes' : 0,\n",
    "        'common_neighbors' : len(set(profile1['neighbors']) & set(profile2['neighbors'])),\n",
    "        'degree' : profile2['degree'],\n",
    "    }\n",
    "\n",
    "    for k in profile1.keys():\n",
    "        if k != 'name' and k != 'neighbors' and k in profile2.keys():\n",
    "            if profile1[k] == profile2[k]:\n",
    "                similarity['common_attributes'] += 1\n",
    "        \n",
    "    return similarity\n",
    "\n",
    "\n",
    "def select_neighbor(G, t, profiles, temperature, num_choices=1, num_samples=-1, dropped_nodes=[], model='gpt-4-1106-preview'):\n",
    "\n",
    "    if num_samples > 0:\n",
    "        choice_set = random.sample([v for v in G.nodes() if v != t and v not in G.neighbors(t)], max(0, num_samples - len(dropped_nodes))) + dropped_nodes\n",
    "    else:\n",
    "        choice_set = [v for v in G.nodes() if v != t and v not in G.neighbors(t)]\n",
    "\n",
    "    candidate_profiles = []\n",
    "\n",
    "    for v in choice_set + [t]:\n",
    "        profiles[v]['neighbors'] = list(G.neighbors(v))\n",
    "        profiles[v]['degree'] = len(profiles[v]['neighbors']) \n",
    "        profiles[v]['name'] = v                 \n",
    "        candidate_profiles.append(profiles[v])\n",
    "\n",
    "    random.shuffle(candidate_profiles)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    # Task\n",
    "    Your task is to select a set of people to be friends with.\n",
    "\n",
    "    # Profile\n",
    "    Your profile is given below after chevrons:\n",
    "    <PROFILE>\n",
    "    {json.dumps(profiles[t])}\n",
    "    </PROFILE>\n",
    "\n",
    "    # Candidate Profiles\n",
    "    The cadidate profiles to be friends with are given below after chevrons:\n",
    "\n",
    "    <PROFILES>\n",
    "    {json.dumps(candidate_profiles)}\n",
    "    </PROFILES>\n",
    "\n",
    "    # Output\n",
    "    The output should be given a list of JSON objects with the following structure\n",
    "\n",
    "    [\n",
    "        {{\n",
    "            \"name\" : name of the person you selected,\n",
    "            \"reason\" : reason for selecting the person\n",
    "        }}, ...\n",
    "    ]\n",
    "\n",
    "    # Notes\n",
    "    * The output must be a list of JSON objects ranked in the order of preference.\n",
    "    * You can make at most {num_choices} selection{'s' if num_choices > 1 else ''}.\n",
    "    \n",
    "    ```json\n",
    "    \"\"\"   \n",
    "\n",
    "    for _ in range(10):\n",
    "        try:\n",
    "            ans = get_response(prompt, temperature=temperature, model=model)\n",
    "            try:\n",
    "                results = json.loads(ans.split('```')[0])\n",
    "            except:\n",
    "                results = json.loads(ans.split('```json')[1].split('```')[0])\n",
    "\n",
    "            filtered_results = []\n",
    "            for result in results:\n",
    "                v = result['name']\n",
    "                if v in G.nodes():\n",
    "                    result['similarity'] = measure_similarity(profiles[t], profiles[v])\n",
    "                    filtered_results.append(result)\n",
    "\n",
    "                    result['dropped'] = v in dropped_nodes\n",
    "\n",
    "            print(f'Node: {t}, Links: {filtered_results}')\n",
    "\n",
    "            candidates = []\n",
    "\n",
    "            for candidate_profile in candidate_profiles:\n",
    "                similarity = measure_similarity(profiles[t], candidate_profile)\n",
    "                candidates.append({'name' : candidate_profile['name'], 'similarity' : similarity})\n",
    "\n",
    "            return filtered_results, candidates\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    return [], []\n",
    "\n",
    "\n",
    "def run_network_formation_experiment(name, num_simulations, outfile, temperatures, method, num_choices, num_samples, num_nodes_samples, model, dataloader_fn):\n",
    "    networks = dataloader_fn()\n",
    "    \n",
    "    saved_scenarios = set()\n",
    "\n",
    "    if os.path.exists(outfile):\n",
    "        with open(outfile) as f:\n",
    "            lines = f.read().splitlines()\n",
    "\n",
    "            for line in lines:\n",
    "                scenario = json.loads(line)\n",
    "                saved_scenarios.add((scenario['name'], scenario['ego'], scenario['simulation'], scenario['temperature'], scenario['num_samples'], scenario['num_choices']))\n",
    "\n",
    "        exit()\n",
    "\n",
    "    f = open(outfile, 'a+')\n",
    "\n",
    "    for ego, G0 in networks.items():\n",
    "        for i in range(num_simulations):\n",
    "            for temperature in temperatures:\n",
    "                if (name, ego, i, temperature, num_samples, num_choices) in saved_scenarios:\n",
    "                    print(f'Skipping simulation for name={name}, ego={ego}, i={i}, temperature={temperature}, num_choices={num_choices}, num_samples={num_samples}, method={method}')\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f'Running simulation for name={name}, ego={ego}, i={i}, temperature={temperature}, num_choices={num_choices}, num_samples={num_samples}, method={method}')\n",
    "\n",
    "                    Gs, results, candidates = network_growth(G0, temperature=temperature, method=method, num_choices=num_choices, num_samples=num_samples, num_nodes_samples=num_nodes_samples, model=model)\n",
    "\n",
    "                    temp = {\n",
    "                        'name' : name,\n",
    "                        'ego' : ego,\n",
    "                        'temperature' : temperature,\n",
    "                        'simulation' : i,\n",
    "                        'num_choices' : num_choices,\n",
    "                        'num_samples' : num_samples,\n",
    "                        'graphs' : [nx.to_dict_of_dicts(G) for G in Gs],\n",
    "                        'results' : results,\n",
    "                        'candidates' : candidates,\n",
    "                        'model' : model\n",
    "                    }    \n",
    "\n",
    "                    f.write(json.dumps(temp) + '\\n')            \n",
    "\n",
    "                if method != 'llm':\n",
    "                    break\n",
    "\n",
    "    f.close()\n",
    "\n",
    "def draw_graph(G, ax, communities=None, palette=None):\n",
    "\n",
    "    pos = nx.spring_layout(G)\n",
    "\n",
    "    netgraph.Graph(G, node_layout=pos, node_color='#d35400', node_size=2.5, edge_color='#34495e', edge_width=1, ax=ax)\n",
    "\n",
    "    ax.set_axis_off()\n",
    "\n",
    "\n",
    "def generate_regression_table(filename, outfile):\n",
    "\n",
    "    palette = ['#d35400', '#34495e', '#2980b9', '#e67e22', '#f1c40f', '#7f8c8d', '#27ae60', '#16a085', '#bdc3c7', '#1abc9c', '#2ecc71', '#3498db', '#9b59b6', '#8e44ad', '#ecf0f1']\n",
    "\n",
    "    with open(filename) as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for line in lines:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "    feature_names = ['degree', 'common_attributes', 'common_neighbors']\n",
    "\n",
    "    regression_table_df = []\n",
    "    \n",
    "    names = set([d['name'] for d in data])\n",
    "\n",
    "\n",
    "    for d in data:\n",
    "        # Gs = []\n",
    "        # for graph in d['graphs']:\n",
    "        #     G = nx.from_dict_of_dicts(graph)\n",
    "        #     Gs.append(G)\n",
    "\n",
    "        log_likelihoods = {}\n",
    "\n",
    "        for num_features in range(len(feature_names) + 1):\n",
    "            for feature_combination in itertools.combinations(feature_names, num_features):\n",
    "                feature_combination = list(feature_combination)\n",
    "                theta, relative_probabilities, log_Z_mean, log_likelihood, standard_errors, choices, choice_sets = fit_discrete_choice_model(d['results'], d['candidates'], feature_names=feature_combination, bias=True)\n",
    "                            \n",
    "                temp = {\n",
    "                    'Name' : d[\"name\"],\n",
    "                    'Ego' : d[\"ego\"],\n",
    "                    'Temperature' : d[\"temperature\"],\n",
    "                    'Simulation' : d[\"simulation\"],\n",
    "                    'Number of Choices' : d[\"num_choices\"],\n",
    "                    'Number of Samples' : d[\"num_samples\"],\n",
    "                    'Independent Variable' : feature_combination,\n",
    "                    'Coefficients' : theta[:-1].tolist(),\n",
    "                    'Standard Errors' : standard_errors[:-1].tolist(),\n",
    "                    'Log Likelihood' : log_likelihood,\n",
    "                }\n",
    "\n",
    "                log_likelihoods[tuple(sorted(feature_combination))] = log_likelihood\n",
    "                p_values = np.array([1 - stats.chi2.cdf(2 * (log_likelihood - log_likelihoods[tuple(sorted(feature_combination[:i] + feature_combination[i + 1:]))]), 1) for i in range(len(feature_combination))])\n",
    "\n",
    "                temp['P-values'] = p_values.tolist()\n",
    "\n",
    "                regression_table_df.append(temp)\n",
    "\n",
    "                choices = np.array(choices)\n",
    "\n",
    "                utilities = np.ones(len(relative_probabilities))\n",
    "                utilities_upper = np.ones(len(relative_probabilities))\n",
    "                utilities_lower = np.ones(len(relative_probabilities))\n",
    "\n",
    "                feat_linspaces = []\n",
    "\n",
    "                for i, feat_name in enumerate(feature_combination):\n",
    "                    feat_linspace = np.linspace(np.min(choices[:, i, 0]), np.max(choices[:, i, 0]), len(relative_probabilities))\n",
    "                    \n",
    "\n",
    "                    utilities *= np.exp(theta[i] * feat_linspace)\n",
    "                    utilities_upper *= np.exp((theta[i] + standard_errors[i]) * feat_linspace)\n",
    "                    utilities_lower *= np.exp((theta[i] - standard_errors[i]) * feat_linspace)\n",
    "\n",
    "                    feat_linspaces.append(feat_linspace)\n",
    "\n",
    "                utilities *= np.exp(theta[-1])\n",
    "                utilities_upper *= np.exp(theta[-1] + standard_errors[-1])\n",
    "                utilities_lower *= np.exp(theta[-1] - standard_errors[-1])\n",
    "\n",
    "                utilities /= np.exp(log_Z_mean)\n",
    "                utilities_upper /= np.exp(log_Z_mean)\n",
    "                utilities_lower /= np.exp(log_Z_mean)\n",
    "\n",
    "        if num_features == 3:\n",
    "            # Plot relative probabilities\n",
    "            fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "            fig.suptitle(f'Joint MNL Model for {d[\"name\"]} (Temperature = {d[\"temperature\"]})')\n",
    "\n",
    "            ax[0].set_ylabel('relative probability (log)')\n",
    "            \n",
    "            for i, feat_name in enumerate(feature_names):\n",
    "                sns.scatterplot(x=choices[:, i, 0], y=np.log(relative_probabilities), ax=ax[i], color=palette[i], s=10, alpha=0.5)\n",
    "                ax[i].set_xlabel(feat_name.replace('_', ' ') + ' (log)')\n",
    "\n",
    "                ax[i].plot(feat_linspaces[i], np.log(utilities), color=palette[i], linewidth=2)\n",
    "                ax[i].fill_between(feat_linspaces[i], np.log(utilities_lower), np.log(utilities_upper), color=palette[i], alpha=0.2)\n",
    "\n",
    "                ax[i].spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "            fig.tight_layout()\n",
    "\n",
    "            fig.savefig(f'figures/combined_model/{d[\"name\"]}_temperature_{d[\"temperature\"]}_simulation_{d[\"simulation\"]}_relative_probabilities.png')\n",
    "\n",
    "\n",
    "    regression_table_df = pd.DataFrame.from_records(regression_table_df)\n",
    "\n",
    "    regression_table_df.to_excel(outfile)\n",
    "\n",
    "\n",
    "def pretty_print_regression_table(filenames, outfile, full=False):\n",
    "\n",
    "    if isinstance(filenames, str):\n",
    "        filenames = [filenames]\n",
    "\n",
    "    regression_table_df = pd.concat([pd.read_excel(filename) for filename in filenames])\n",
    "\n",
    "    regression_table_df = regression_table_df.query('`Independent Variable` != \"[]\"')\n",
    "\n",
    "    table_rows_df = []\n",
    "\n",
    "    ego_row = True\n",
    "\n",
    "    temperature2idx = {}\n",
    "\n",
    "\n",
    "    for i, row in regression_table_df.iterrows():\n",
    "        temp = {}\n",
    "        if row['Ego'] == -1:\n",
    "            ego_row = False\n",
    "        else:\n",
    "            temp['Ego'] = row['Ego']\n",
    "        temp['Temperature'] = row['Temperature']\n",
    "\n",
    "        if row['Temperature'] not in temperature2idx:\n",
    "            temperature2idx[row['Temperature']] = len(temperature2idx)\n",
    "\n",
    "        independent_variables = ast.literal_eval(row['Independent Variable'])\n",
    "\n",
    "        if (not full and len(independent_variables) ==  3) or full:\n",
    "\n",
    "            p_values = ast.literal_eval(row['P-values'])\n",
    "            coefficients = ast.literal_eval(row['Coefficients'])\n",
    "            standard_errors = ast.literal_eval(row['Standard Errors'])\n",
    "\n",
    "            for j, feat_name in enumerate(independent_variables):\n",
    "                stars = '***' if float(p_values[j]) < 0.001 else '**' if float(p_values[j]) < 0.01 else '*' if float(p_values[j]) < 0.05 else ''\n",
    "                temp[f'{feat_name.replace(\"_\", \" \").capitalize()}'] = f\"{float(coefficients[j]):.2f}{stars} ({float(standard_errors[j]):.2f})\"\n",
    "\n",
    "\n",
    "          \n",
    "\n",
    "            temp['Log Likelihood'] = f\"{row['Log Likelihood']:,.2f}\"\n",
    "            temp['AIC'] = f'{2 * (len(independent_variables) + 1) - 2 * row[\"Log Likelihood\"]:,.2f}'\n",
    "\n",
    "          \n",
    "          \n",
    "            table_rows_df.append(temp)\n",
    "\n",
    "\n",
    "    table_rows_df = pd.DataFrame.from_records(table_rows_df, columns=['Ego'] if ego_row else [] +  ['Temperature', 'Degree', 'Common attributes', 'Common neighbors', 'Log Likelihood', 'AIC'])\n",
    "    table_rows_df = table_rows_df.fillna(' ')\n",
    "\n",
    "    table_rows_df.to_latex(outfile, index=False, escape=True, column_format='lcccccc')\n",
    "\n",
    "\n",
    "def plot_coefficients(filenames, outfile):\n",
    "\n",
    "    palette = ['#d35400', '#34495e', '#2980b9', '#e67e22', '#f1c40f', '#7f8c8d', '#27ae60', '#16a085', '#bdc3c7', '#1abc9c', '#2ecc71', '#3498db', '#9b59b6', '#8e44ad', '#ecf0f1']\n",
    "\n",
    "    if isinstance(filenames, str):\n",
    "        filenames = [filenames]\n",
    "\n",
    "    regression_table_df = pd.concat([pd.read_excel(filename) for filename in filenames])\n",
    "\n",
    "    regression_table_df = regression_table_df.query('`Independent Variable` != \"[]\"')\n",
    "\n",
    "    table_rows_df = []\n",
    "\n",
    "    ego_row = True\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    temperature2idx = {}\n",
    "\n",
    "    name2idx = {}\n",
    "\n",
    "    variables2latex = {\n",
    "        'degree' : '$\\\\hat \\\\theta_{PA}$',\n",
    "        'common_attributes' : '$\\\\hat \\\\theta_{H}$',\n",
    "        'common_neighbors' : '$\\\\hat \\\\theta_{TC}$',\n",
    "    }\n",
    "\n",
    "    for i, row in regression_table_df.iterrows():\n",
    "        if row['Name'] not in name2idx:\n",
    "            name2idx[row['Name']] = len(name2idx)\n",
    "\n",
    "    for i, row in regression_table_df.iterrows():\n",
    "        temp = {}\n",
    "        if row['Ego'] == -1:\n",
    "            ego_row = False\n",
    "        else:\n",
    "            temp['Ego'] = row['Ego']\n",
    "        temp['Temperature'] = row['Temperature']\n",
    "\n",
    "        if row['Temperature'] not in temperature2idx:\n",
    "            temperature2idx[row['Temperature']] = len(temperature2idx)\n",
    "\n",
    "        independent_variables = ast.literal_eval(row['Independent Variable'])\n",
    "\n",
    "        if len(independent_variables) ==  3:\n",
    "\n",
    "            p_values = ast.literal_eval(row['P-values'])\n",
    "            coefficients = ast.literal_eval(row['Coefficients'])\n",
    "            standard_errors = ast.literal_eval(row['Standard Errors'])\n",
    "\n",
    "            for j, feat_name in enumerate(independent_variables):\n",
    "                stars = '***' if float(p_values[j]) < 0.001 else '**' if float(p_values[j]) < 0.01 else '*' if float(p_values[j]) < 0.05 else ''\n",
    "                temp[f'{feat_name.replace(\"_\", \" \").capitalize()}'] = f\"{float(coefficients[j]):.2f}{stars} ({float(standard_errors[j]):.2f})\"\n",
    "\n",
    "\n",
    "                if len(independent_variables) ==  3:\n",
    "                    l = 0.3\n",
    "                    j_pos = 2 * l * name2idx[row['Name']] / (len(name2idx) - 1) + j - l\n",
    "                    if j == 0:\n",
    "                        ax[temperature2idx[row['Temperature']]].errorbar(float(coefficients[j]), j_pos, xerr=float(standard_errors[j]), fmt='o', color=palette[name2idx[row['Name']]], capsize=5, label=row['Name'])\n",
    "                    else:\n",
    "                        ax[temperature2idx[row['Temperature']]].errorbar(float(coefficients[j]), j_pos, xerr=float(standard_errors[j]), fmt='o', color=palette[name2idx[row['Name']]], capsize=5)\n",
    "\n",
    "            if len(independent_variables) ==  3:\n",
    "\n",
    "                ax[temperature2idx[row['Temperature']]].set_ylim(-1, 3)\n",
    "                ax[temperature2idx[row['Temperature']]].set_yticks(range(len(independent_variables)))\n",
    "                ax[temperature2idx[row['Temperature']]].set_yticklabels([variables2latex[feat_name] for feat_name in independent_variables])\n",
    "                ax[temperature2idx[row['Temperature']]].set_title(f'Temperature = {row[\"Temperature\"]}')\n",
    "                ax[temperature2idx[row['Temperature']]].set_xlim(-0.25, 2.75)\n",
    "                ax[temperature2idx[row['Temperature']]].plot([0, 0], [-1, 3], color='#7f8c8d', linewidth=1.0, linestyle='--')\n",
    "\n",
    "    for i in range(len(temperature2idx)):\n",
    "        ax[i].spines[['right', 'top']].set_visible(False)\n",
    "        if i == len(temperature2idx) - 1:\n",
    "            ax[i].legend(fontsize=0.5*SMALL_SIZE, loc='lower right')\n",
    "          \n",
    "    fig.tight_layout()\n",
    "    fig.savefig(outfile, dpi=300, bbox_inches='tight')\n",
    "            \n",
    "\n",
    "def prepare_discrete_choice_model(results, candidates, bias=True, feature_names=['degree'], log_transform=True):\n",
    "\n",
    "    choice_sets = []\n",
    "    choices = []\n",
    "\n",
    "    for result in results:\n",
    "        num_choices = len(result)\n",
    "        choice = np.ones((len(feature_names) + int(bias), num_choices))\n",
    "        for i, r in enumerate(result):\n",
    "            for j, feat_name in enumerate(feature_names):\n",
    "                if log_transform:\n",
    "                    choice[j, i] = np.log(r['similarity'][feat_name] + 1)\n",
    "                else:\n",
    "                    choice[j, i] = r['similarity'][feat_name]\n",
    "\n",
    "        choices.append(choice)\n",
    "\n",
    "        \n",
    "\n",
    "    for candidate in candidates:\n",
    "        choice_set = np.ones((len(feature_names) + int(bias), len(candidate)))\n",
    "\n",
    "        for i, c in enumerate(candidate):\n",
    "            for j, feat_name in enumerate(feature_names):\n",
    "                if log_transform:\n",
    "                    choice_set[j, i] = np.log(c['similarity'][feat_name] + 1)\n",
    "                else:\n",
    "                    choice_set[j, i] = c['similarity'][feat_name]\n",
    "\n",
    "        choice_sets.append(choice_set)\n",
    "    \n",
    "    return choices, choice_sets\n",
    "\n",
    "\n",
    "def fit_discrete_choice_model(results, candidates, bias=True, feature_names=['degree', 'common_attributes', 'common_neighbors'], log_transform=True):\n",
    "\n",
    "    choices, choice_sets = prepare_discrete_choice_model(results, candidates, bias=bias, feature_names=feature_names, log_transform=log_transform)\n",
    "\n",
    "    theta = np.zeros(len(feature_names) + int(bias))\n",
    "\n",
    "    ll = lambda x: -discrete_choice_model_log_likelihood(x, choice_sets, choices)\n",
    "\n",
    "    res = scipy.optimize.minimize(ll, x0=theta, method='L-BFGS-B')\n",
    "\n",
    "    theta = res.x\n",
    "\n",
    "    log_likelihood = -res.fun\n",
    "\n",
    "    standard_errors = res.hess_inv.todense().diagonal() ** 0.5\n",
    "\n",
    "    relative_probabilities, log_Z_mean = discrete_choice_model_relative_probability(theta, choice_sets, choices)\n",
    "\n",
    "    return theta, relative_probabilities, log_Z_mean, log_likelihood, standard_errors, choices, choice_sets\n",
    "\n",
    "\n",
    "def discrete_choice_model_log_likelihood(theta, choice_sets, choices):\n",
    "\n",
    "    log_likelihood = 0\n",
    "\n",
    "    for choice_set, choice in zip(choice_sets, choices):\n",
    "        choice_set_utilities = np.dot(theta, choice_set)\n",
    "        Z = np.sum(np.exp(choice_set_utilities))\n",
    "\n",
    "        num_choices = choice.shape[1]\n",
    "\n",
    "        for i in range(num_choices):\n",
    "            choice_utility = np.dot(theta, choice[:, i])\n",
    "            log_likelihood += choice_utility - np.log(Z)\n",
    "\n",
    "    return log_likelihood\n",
    "\n",
    "def discrete_choice_model_relative_probability(theta, choice_sets, choices):\n",
    "    probabilities = []\n",
    "    Zs = []\n",
    "    for choice_set, choice in zip(choice_sets, choices):\n",
    "        choice_set_utilities = np.dot(theta, choice_set)\n",
    "        Z = np.sum(np.exp(choice_set_utilities))\n",
    "        Zs.append(np.log(Z))\n",
    "\n",
    "        num_choices = choice.shape[1]\n",
    "\n",
    "        for i in range(num_choices):\n",
    "            choice_utility = np.dot(theta, choice[:, i])\n",
    "            probabilities.append(np.exp(choice_utility) / Z)\n",
    "\n",
    "    return np.array(probabilities), np.mean(Zs)\n",
    "\n",
    "def modularity_change(filenames, subgraph=False):\n",
    "\n",
    "    for filename in filenames:\n",
    "\n",
    "        with open(filename) as f:\n",
    "            lines = f.read().splitlines()\n",
    "\n",
    "        for line in lines:\n",
    "            temp = json.loads(line)\n",
    "\n",
    "            G0 = nx.from_dict_of_dicts(temp['graphs'][0])\n",
    "            G1 = nx.from_dict_of_dicts(temp['graphs'][-1])\n",
    "\n",
    "            if subgraph:\n",
    "                H = nx.difference(G1, G0)\n",
    "                H.remove_nodes_from(list(nx.isolates(H)))                \n",
    "                G0 = nx.subgraph(G0, H.nodes())\n",
    "                G1 = nx.subgraph(G1, H.nodes())\n",
    "\n",
    "            modularities0 = []\n",
    "            modularities1 = []\n",
    "\n",
    "            for seed in range(10):\n",
    "                communities0 = nx.community.louvain_communities(G0, seed=seed)\n",
    "                modularities0.append(nx.community.modularity(G0, communities0))\n",
    "\n",
    "                communities1 = nx.community.louvain_communities(G1, seed=seed)\n",
    "                modularities1.append(nx.community.modularity(G1, communities1))\n",
    "\n",
    "\n",
    "            t, p = stats.ttest_ind(modularities0, modularities1, equal_var=False, alternative='less')\n",
    "\n",
    "            print(f'{temp[\"name\"]}, {temp[\"temperature\"]}, T-test: {t}, p-value: {p}')\n",
    "\n",
    "def lcc(G):\n",
    "    Gcc = sorted(nx.connected_components(G), key=len, reverse=True)\n",
    "    return G.subgraph(Gcc[0])\n",
    "\n",
    "def small_worldness(filenames, name, dataloader_fn, subgraph=False):\n",
    "\n",
    "    networks = dataloader_fn()\n",
    "\n",
    "    G_initial = networks[list(networks.keys())[0]]\n",
    "\n",
    "    # LCC subgraph\n",
    "    G_initial = lcc(G_initial)\n",
    "\n",
    "    average_shortest_path_length_initial = nx.average_shortest_path_length(G_initial)\n",
    "    clustering_coefficient_initial = nx.average_clustering(G_initial)\n",
    "\n",
    "    for filename in filenames:\n",
    "\n",
    "            with open(filename) as f:\n",
    "                lines = f.read().splitlines()\n",
    "\n",
    "            for line in lines:\n",
    "                temp = json.loads(line)\n",
    "\n",
    "                G0 = nx.from_dict_of_dicts(temp['graphs'][0])\n",
    "                G1 = nx.from_dict_of_dicts(temp['graphs'][-1])\n",
    "\n",
    "                G1 = lcc(G1)\n",
    "                # if subgraph:\n",
    "                #     H = nx.difference(G1, G0)\n",
    "                #     H.remove_nodes_from(list(nx.isolates(H)))                \n",
    "                #     G0 = nx.subgraph(G0, H.nodes())\n",
    "                #     G1 = nx.subgraph(G1, H.nodes())\n",
    "\n",
    "                average_shortest_path_length = nx.average_shortest_path_length(G1)\n",
    "                clustering_coefficient = nx.average_clustering(G1)\n",
    "\n",
    "                average_shortest_path_length_initial_change = (average_shortest_path_length - average_shortest_path_length_initial) / average_shortest_path_length_initial * 100\n",
    "                clustering_coefficient_initial_change = (clustering_coefficient - clustering_coefficient_initial) / clustering_coefficient_initial * 100\n",
    "\n",
    "                print(f'{temp[\"name\"]}, {temp[\"temperature\"]}, Average Shortest Path Length Change: {average_shortest_path_length_initial_change}, Clustering Coefficient Change: {clustering_coefficient_initial_change}')\n",
    "\n",
    "def measure_relative_increase(filenames):\n",
    "\n",
    "    for filename in filenames:\n",
    "\n",
    "        with open(filename) as f:\n",
    "            lines = f.read().splitlines()\n",
    "\n",
    "        data = []\n",
    "\n",
    "        for line in lines:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "        for d in data:\n",
    "            total, count = 0, 0        \n",
    "            for results in d[\"results\"]:\n",
    "                for result in results:\n",
    "                    count += int(result['dropped'])\n",
    "                    total += 1          \n",
    "\n",
    "            accuracy = count / total * 100\n",
    "            random_guess = 100 / d[\"num_choices\"]\n",
    "            relative_increase = (accuracy - random_guess) / random_guess * 100\n",
    "\n",
    "            print(f'{d[\"name\"]}, {d[\"temperature\"]}, {d[\"simulation\"]}, Relative Increase in Accuracy % = {relative_increase}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta/meta-llama-3-70b-instruct\n",
      "Running simulation for name=Caltech36, ego=-1, i=0, temperature=0.5, num_choices=1, num_samples=15, method=llm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8n/s26krq6n1vb_73jtxvb8k8th0000gn/T/ipykernel_76757/657748870.py:221: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  nodes = random.sample(G.nodes(), min(len(G), num_nodes_samples))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: 394, Links: [{'name': 394, 'reason': 'Same major, second major, year, high school, and many common neighbors, indicating a strong connection and shared background.', 'similarity': {'common_attributes': 6, 'common_neighbors': 45, 'degree': 45}, 'dropped': False}]\n",
      "list index out of range\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m outfile \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs/combined_model_facebook100_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_whole_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m+\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m dataloader_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: dataloader\u001b[38;5;241m.\u001b[39mload_facebook100(input_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatasets/facebook100\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39mname, num_egonets\u001b[38;5;241m=\u001b[39mnum_egonets, egonets_radius\u001b[38;5;241m=\u001b[39megonets_radius, sample_egonets\u001b[38;5;241m=\u001b[39msample_egonets)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mrun_network_formation_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_simulations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mllm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_choices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 436\u001b[0m, in \u001b[0;36mrun_network_formation_experiment\u001b[0;34m(name, num_simulations, outfile, temperatures, method, num_choices, num_samples, num_nodes_samples, model, dataloader_fn)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning simulation for name=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, ego=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mego\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, i=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, temperature=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemperature\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, num_choices=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_choices\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, method=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 436\u001b[0m     Gs, results, candidates \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork_growth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_choices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_choices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_nodes_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m     temp \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    439\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m : name,\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mego\u001b[39m\u001b[38;5;124m'\u001b[39m : ego,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m : model\n\u001b[1;32m    449\u001b[0m     }    \n\u001b[1;32m    451\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(json\u001b[38;5;241m.\u001b[39mdumps(temp) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)            \n",
      "Cell \u001b[0;32mIn[1], line 248\u001b[0m, in \u001b[0;36mnetwork_growth\u001b[0;34m(G0, temperature, num_choices, method, num_samples, num_nodes_samples, model)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(nodes):\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllm\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 248\u001b[0m         result, candidate \u001b[38;5;241m=\u001b[39m \u001b[43mselect_neighbor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_choices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdropped_edges\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropped_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdropped_edges\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    251\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result:\n",
      "Cell \u001b[0;32mIn[1], line 380\u001b[0m, in \u001b[0;36mselect_neighbor\u001b[0;34m(G, t, profiles, temperature, num_choices, num_samples, dropped_nodes, model)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m         ans \u001b[38;5;241m=\u001b[39m \u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    382\u001b[0m             results \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(ans\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/workspace/llm-network-formation/utils.py:77\u001b[0m, in \u001b[0;36mget_response\u001b[0;34m(prompt, model, temperature, system_prompt)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m replicate_client\n\u001b[1;32m     72\u001b[0m replicate_input \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m : prompt,\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m'\u001b[39m : temperature,\n\u001b[1;32m     75\u001b[0m }\n\u001b[0;32m---> 77\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mreplicate_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplicate_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(result)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/replicate/client.py:173\u001b[0m, in \u001b[0;36mClient.run\u001b[0;34m(self, ref, input, **params)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    165\u001b[0m     ref: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28minput\u001b[39m: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams: Unpack[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions.CreatePredictionParams\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    168\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Any, Iterator[Any]]:  \u001b[38;5;66;03m# noqa: ANN401\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m    Run a model and wait for its output.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/replicate/run.py:58\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(client, ref, input, **params)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;129;01mand\u001b[39;00m (iterator \u001b[38;5;241m:=\u001b[39m _make_output_iterator(version, prediction)):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m iterator\n\u001b[0;32m---> 58\u001b[0m \u001b[43mprediction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ModelError(prediction)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/replicate/prediction.py:145\u001b[0m, in \u001b[0;36mPrediction.wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msucceeded\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcanceled\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    144\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpoll_interval)\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/replicate/prediction.py:223\u001b[0m, in \u001b[0;36mPrediction.reload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m    Load this prediction from the server.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m     updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m updated\u001b[38;5;241m.\u001b[39mdict()\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/replicate/prediction.py:353\u001b[0m, in \u001b[0;36mPredictions.get\u001b[0;34m(self, id)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mid\u001b[39m: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Prediction:\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03m    Get a prediction by ID.\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;124;03m        Prediction: The prediction object.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/v1/predictions/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _json_to_prediction(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client, resp\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/replicate/client.py:88\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, method, path, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, method: \u001b[38;5;28mstr\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m httpx\u001b[38;5;241m.\u001b[39mResponse:\n\u001b[0;32m---> 88\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     _raise_for_status(resp)\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/httpx/_client.py:837\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    822\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m    824\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    825\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    826\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    835\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    836\u001b[0m )\n\u001b[0;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/httpx/_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/httpx/_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/httpx/_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    989\u001b[0m     hook(request)\n\u001b[0;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/httpx/_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/replicate/client.py:283\u001b[0m, in \u001b[0;36mRetryTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandle_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: httpx\u001b[38;5;241m.\u001b[39mRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m httpx\u001b[38;5;241m.\u001b[39mResponse:\n\u001b[0;32m--> 283\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_transport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m request\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretryable_methods:\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/httpx/_transports/default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    245\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/ssl.py:1259\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1256\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1257\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1258\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/ssl.py:1132\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Run simulations\n",
    "models = ['meta/meta-llama-3-70b-instruct', 'gpt-4o-mini', 'claude-3-5-sonnet-20240620']\n",
    "num_egonets = -1\n",
    "egonets_radius = -1\n",
    "sample_egonets = False\n",
    "\n",
    "for model in models:\n",
    "    print(model)\n",
    "    for name in ['Caltech36', 'Swarthmore42', 'UChicago30']:\n",
    "        for i, temperature in enumerate([0.5, 1.0, 1.5], 1):\n",
    "            outfile = f'outputs/combined_model_facebook100_{name.lower()}_whole_{i}+{model.replace(\"/\", \"-\")}.jsonl'\n",
    "            dataloader_fn = lambda: dataloader.load_facebook100(input_dir='datasets/facebook100', name=name, num_egonets=num_egonets, egonets_radius=egonets_radius, sample_egonets=sample_egonets)\n",
    "            run_network_formation_experiment(name=name, num_nodes_samples=3000, num_simulations=1, outfile=outfile, temperatures=[temperature], method='llm', num_choices=1, num_samples=15, model=model, dataloader_fn=dataloader_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and format regression tables\n",
    "for model in models:\n",
    "    for name in ['Caltech36', 'Swarthmore42', 'UChicago30']:\n",
    "        for i in range(1, 4):\n",
    "            generate_regression_table(f'outputs/combined_model_facebook100_{name.lower()}_whole_{i}+{model.replace(\"/\", \"-\")}.jsonl', f'tables/combined_model_facebook100_{name.lower()}_whole_{i}+{model.replace(\"/\", \"-\")}.xlsx')\n",
    "\n",
    "# Export regression tables to LaTeX\n",
    "for model in models:\n",
    "    for name in ['Caltech36', 'Swarthmore42', 'UChicago30']:\n",
    "        for full in [True, False]:\n",
    "            pretty_print_regression_table([f'tables/combined_model_facebook100_{name.lower()}_whole_{i}+{model.replace(\"/\", \"-\")}.xlsx' for i in range(1, 4)], f'tables/combined_model_facebook100_{name.lower()}{\"_full\" if full else \"\"}+{model.replace(\"/\", \"-\")}.tex', full=full)\n",
    "\n",
    "    plot_coefficients([f'tables/combined_model_facebook100_{name.lower()}_whole_{i}+{model.replace(\"/\", \"-\")}.xlsx' for i in range(1, 4) for name in ['Caltech36', 'Swarthmore42', 'UChicago30']], f'figures/combined_model_facebook100_coefficients+{model.replace(\"/\", \"-\")}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Community structure\n",
    "for model in models:\n",
    "    for name in ['Caltech36', 'Swarthmore42', 'UChicago30']:\n",
    "        modularity_change([f'outputs/combined_model_facebook100_{name.lower()}_whole_{i}+{model.replace(\"/\", \"-\")}.jsonl' for i in range(1, 4)], subgraph=False)\n",
    "        if name == 'UChicago30':\n",
    "            modularity_change([f'outputs/combined_model_facebook100_{name.lower()}_whole_{i}+{model.replace(\"/\", \"-\")}.jsonl' for i in range(1, 4)], subgraph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_egonets = -1\n",
    "egonets_radius = -1\n",
    "sample_egonets = False\n",
    "\n",
    "for model in models:\n",
    "    for name in ['Caltech36', 'Swarthmore42', 'UChicago30']:\n",
    "        dataloader_fn = lambda: dataloader.load_facebook100(input_dir='datasets/facebook100', name=name, num_egonets=num_egonets, egonets_radius=egonets_radius, sample_egonets=sample_egonets)\n",
    "        small_worldness([f'outputs/combined_model_facebook100_{name.lower()}_whole_{i}+{model.replace(\"/\", \"-\")}.jsonl' for i in range(1, 4)], name, subgraph=False, dataloader_fn=dataloader_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative increase in accuracy compared to random baseline\n",
    "for model in models:\n",
    "    for name in ['Caltech36', 'Swarthmore42', 'UChicago30']:\n",
    "        measure_relative_increase([f'outputs/combined_model_facebook100_{name.lower()}_whole_{i}_small+{model.replace(\"/\", \"-\")}.jsonl' for i in range(1, 4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM reasoning\n",
    "\n",
    "# categories = [{'category' : 'Number of friends', 'description' : 'Large number of friends'},\n",
    "#               {'category' : 'Mutual friends', 'description' : 'Large number of mutual friends'},\n",
    "#               {'category' : 'Similar attributes', 'description' : 'Similar attributes such as major, faculty status, etc.'}]\n",
    "\n",
    "# for model in models:\n",
    "#     for name in ['Caltech36', 'Swarthmore42', 'UChicago30']:\n",
    "#         summarize_reasons([f'outputs/combined_model_facebook100_{name.lower()}_whole_{i}.jsonl' for i in range(1, 4)], 'UChicago30', n_samples=20, n_categories=3, n_resamples=2, categories=categories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
